#!/usr/bin/env python3
"""
æµ‹è¯• Qwen2.5-1.5B æ¨¡å‹çš„è®­ç»ƒæ•ˆæœ
å¯¹æ¯”è®­ç»ƒå‰åçš„å›ç­”è´¨é‡
"""

import sys
from pathlib import Path

# æ·»åŠ srcåˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent / "src"))

from inference import ModelInferencer


def test_model():
    """æµ‹è¯•è®­ç»ƒå¥½çš„æ¨¡å‹"""

    print("=" * 70)
    print("æµ‹è¯• Qwen2.5-1.5B æ¨¡å‹æ•ˆæœ")
    print("=" * 70)

    # æ¨¡å‹è·¯å¾„
    model_path = "outputs/trained_model_15b"
    base_model = "models/Qwen/Qwen2.5-1.5B"

    # æµ‹è¯•é—®é¢˜é›†ï¼ˆæ¥è‡ªåŸå§‹è®­ç»ƒæ•°æ®ï¼‰
    test_cases = [
        {
            "question": "å¯¹äºè¯¾é¢˜åä½œè´¹ã€åˆ¶ä½œè´¹ã€ææ–™è´¹ã€å°åˆ·è´¹ã€æµ‹è¯•è´¹ã€åŠ å·¥è´¹ç­‰è´¹ç”¨ï¼Œä»¥åŠè®¾å¤‡é‡‡è´­ï¼Œåä¸œå¸ˆèŒƒå¤§å­¦å¯¹åè®®å’ŒåˆåŒçš„ç­¾è®¢é‡‘é¢æœ‰ä»€ä¹ˆå…·ä½“è¦æ±‚ï¼Ÿ",
            "expected_keywords": ["3000", "åè®®", "10000", "åˆåŒ", "30000", "è®¾å¤‡"],
            "description": "æµ‹è¯•é‡‘é¢è®°å¿†å‡†ç¡®æ€§"
        },
        {
            "question": "åŒä¸€å®¶å•ä½å‘ç¥¨å•å¼ æˆ–ç´¯è®¡é‡‘é¢è¾¾åˆ°å¤šå°‘å…ƒéœ€è¦åè®®ï¼Ÿå¤šå°‘å…ƒéœ€è¦åˆåŒï¼Ÿ",
            "expected_keywords": ["3000", "åè®®", "10000", "åˆåŒ"],
            "description": "æµ‹è¯•åè®®å’ŒåˆåŒé‡‘é¢é—¨æ§›"
        },
        {
            "question": "å¦‚æœåªæœ‰ä¸€å®¶ä»¥ä¸Š(å«)ä¸åŒå®¢æˆ·çš„å•ä½å…±åŒç”³è¯·æŠ¥é”€è´¹ç”¨ï¼Œå¦‚ä½•å¤„ç†ï¼Ÿ",
            "expected_keywords": ["åˆ†åˆ«", "åè®®", "åˆåŒ"],
            "description": "æµ‹è¯•å¤šå®¢æˆ·æŠ¥é”€è§„åˆ™"
        },
        {
            "question": "è´­ä¹°ç‰©å“ä¸ºè®¾å¤‡æ—¶ï¼Œåè®®å’ŒåˆåŒçš„é‡‘é¢è¦æ±‚æ˜¯å¤šå°‘ï¼Ÿ",
            "expected_keywords": ["10000", "åè®®", "30000", "åˆåŒ"],
            "description": "æµ‹è¯•è®¾å¤‡é‡‡è´­ç‰¹æ®Šè§„å®š"
        },
    ]

    try:
        print(f"\næ­£åœ¨åŠ è½½æ¨¡å‹...")
        print(f"  æ¨¡å‹è·¯å¾„: {model_path}")
        print(f"  åŸºåº§æ¨¡å‹: {base_model}")

        # åˆå§‹åŒ–æ¨ç†å™¨
        inferencer = ModelInferencer(model_path, base_model)
        inferencer.load_model()

        print("\n" + "=" * 70)
        print("å¼€å§‹æµ‹è¯•...")
        print("=" * 70)

        # ç»Ÿè®¡ç»“æœ
        total_tests = len(test_cases)
        passed_tests = 0

        for i, test_case in enumerate(test_cases, 1):
            question = test_case["question"]
            expected_keywords = test_case["expected_keywords"]
            description = test_case["description"]

            print(f"\n{'=' * 70}")
            print(f"æµ‹è¯• {i}/{total_tests}: {description}")
            print(f"{'=' * 70}")
            print(f"\né—®é¢˜: {question}")

            # ç”Ÿæˆå›ç­”ï¼ˆä½¿ç”¨è¾ƒä½æ¸©åº¦ä»¥è·å¾—æ›´ç¡®å®šçš„ç»“æœï¼‰
            response = inferencer.generate(
                question,
                max_new_tokens=300,
                temperature=0.1,  # ä½æ¸©åº¦ï¼Œå‡å°‘éšæœºæ€§
                top_p=0.95,
                repetition_penalty=1.1,
            )

            print(f"\nå›ç­”: {response}")

            # æ£€æŸ¥æ˜¯å¦åŒ…å«å…³é”®è¯
            found_keywords = []
            missing_keywords = []

            for keyword in expected_keywords:
                if keyword in response:
                    found_keywords.append(keyword)
                else:
                    missing_keywords.append(keyword)

            # åˆ¤æ–­æ˜¯å¦é€šè¿‡
            passed = len(found_keywords) >= len(expected_keywords) * 0.6  # 60%å…³é”®è¯å‡ºç°å³å¯

            if passed:
                passed_tests += 1
                print(f"\nâœ… é€šè¿‡")
            else:
                print(f"\nâŒ æœªé€šè¿‡")

            print(f"  æ‰¾åˆ°å…³é”®è¯: {', '.join(found_keywords) if found_keywords else 'æ— '}")
            print(f"  ç¼ºå¤±å…³é”®è¯: {', '.join(missing_keywords) if missing_keywords else 'æ— '}")
            print(f"  å…³é”®è¯è¦†ç›–ç‡: {len(found_keywords)}/{len(expected_keywords)} ({len(found_keywords)/len(expected_keywords)*100:.1f}%)")

        # æ€»ç»“
        print("\n" + "=" * 70)
        print("æµ‹è¯•æ€»ç»“")
        print("=" * 70)
        print(f"\næ€»æµ‹è¯•æ•°: {total_tests}")
        print(f"é€šè¿‡æ•°: {passed_tests}")
        print(f"å¤±è´¥æ•°: {total_tests - passed_tests}")
        print(f"é€šè¿‡ç‡: {passed_tests/total_tests*100:.1f}%")

        # ä¸ 0.5B æ¨¡å‹å¯¹æ¯”
        print("\n" + "-" * 70)
        print("ä¸ 0.5B æ¨¡å‹å¯¹æ¯”")
        print("-" * 70)
        print("0.5B æ¨¡å‹é€šè¿‡ç‡: 0% (0/3)")
        print(f"1.5B æ¨¡å‹é€šè¿‡ç‡: {passed_tests/total_tests*100:.1f}% ({passed_tests}/{total_tests})")

        if passed_tests >= total_tests * 0.5:
            print("\nğŸ‰ 1.5B æ¨¡å‹æ˜¾è‘—ä¼˜äº 0.5B æ¨¡å‹ï¼")
            print("   å‡çº§åŸºåº§æ¨¡å‹æœ‰æ•ˆè§£å†³äº†æ¨¡å‹å®¹é‡ä¸è¶³çš„é—®é¢˜ã€‚")
        elif passed_tests > 0:
            print("\nâœ… 1.5B æ¨¡å‹æœ‰æ‰€æ”¹è¿›ï¼Œä½†ä»éœ€ä¼˜åŒ–ã€‚")
            print("   å»ºè®®ï¼šå¢åŠ è®­ç»ƒæ•°æ®é‡ï¼ˆå½“å‰217æ¡ï¼Œå»ºè®®500-1000æ¡ï¼‰")
        else:
            print("\nâš ï¸  1.5B æ¨¡å‹ä»æœªè¾¾åˆ°é¢„æœŸæ•ˆæœã€‚")
            print("   å¯èƒ½åŸå› ï¼š")
            print("   1. è®­ç»ƒæ•°æ®é‡ä¸è¶³ï¼ˆ217æ¡è¾ƒå°‘ï¼‰")
            print("   2. è®­ç»ƒå‚æ•°éœ€è¦è°ƒæ•´")
            print("   3. éœ€è¦æ›´å¤šè®­ç»ƒè½®æ¬¡")

        return passed_tests >= total_tests * 0.5

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = test_model()

    print("\nä¸‹ä¸€æ­¥å»ºè®®:")
    if success:
        print("  1. âœ… 1.5B æ¨¡å‹æ•ˆæœè‰¯å¥½ï¼Œå¯ä»¥ç”¨äºç”Ÿäº§ç¯å¢ƒ")
        print("  2. è€ƒè™‘å¢åŠ æ›´å¤šè®­ç»ƒæ•°æ®ä»¥è¿›ä¸€æ­¥æå‡æ•ˆæœ")
        print("  3. å¯ä»¥å°è¯•åœ¨å…¶ä»–é¢†åŸŸåº”ç”¨æ­¤æ–¹æ¡ˆ")
    else:
        print("  1. ğŸ“Š å¢åŠ è®­ç»ƒæ•°æ®é‡ï¼ˆå½“å‰217æ¡ â†’ ç›®æ ‡500-1000æ¡ï¼‰")
        print("  2. ğŸ”§ è°ƒæ•´è®­ç»ƒå‚æ•°ï¼ˆå­¦ä¹ ç‡ã€è½®æ•°ã€LoRA rankï¼‰")
        print("  3. ğŸ“ æ£€æŸ¥è®­ç»ƒæ•°æ®è´¨é‡")
        print("  4. ğŸ”„ è€ƒè™‘ä½¿ç”¨æ›´å¤§çš„æ¨¡å‹ï¼ˆå¦‚3Bï¼‰")
