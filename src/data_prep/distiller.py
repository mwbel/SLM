"""æ•°æ®è’¸é¦æ¨¡å— - ä½¿ç”¨Gemini APIè¿›è¡ŒçŸ¥è¯†è’¸é¦"""

import os
import json
import sys
from pathlib import Path
from typing import List, Dict, Optional

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„ä»¥æ”¯æŒå¯¼å…¥
sys.path.insert(0, str(Path(__file__).parent.parent))

from google import genai
from google.genai import types
from utils.api_key_rotator import APIKeyRotator


def extract_text(file_path: str) -> str:
    """
    æå–æ–‡ä»¶æ–‡æœ¬å†…å®¹

    Args:
        file_path: æ–‡ä»¶è·¯å¾„ï¼ˆæ”¯æŒPDFå’ŒTXTï¼‰

    Returns:
        æå–çš„æ–‡æœ¬å†…å®¹

    Raises:
        ValueError: ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼
        FileNotFoundError: æ–‡ä»¶ä¸å­˜åœ¨
    """
    file_path = Path(file_path)

    if not file_path.exists():
        raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")

    file_ext = file_path.suffix.lower()

    if file_ext == '.txt':
        # æå–TXTæ–‡ä»¶
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()

    elif file_ext == '.pdf':
        # æå–PDFæ–‡ä»¶ - ä½¿ç”¨PyMuPDF (fitz)
        try:
            import fitz  # PyMuPDF
            doc = fitz.open(file_path)
            text = ""
            for page in doc:
                text += page.get_text()
            doc.close()
            return text
        except ImportError:
            # å¦‚æœPyMuPDFä¸å¯ç”¨ï¼Œå°è¯•ä½¿ç”¨pdfminer.six
            try:
                from pdfminer.high_level import extract_text as pdf_extract
                return pdf_extract(str(file_path))
            except ImportError:
                raise ImportError(
                    "è¯·å®‰è£…PDFå¤„ç†åº“: pip install PyMuPDF æˆ– pip install pdfminer.six"
                )

    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_ext}ï¼Œä»…æ”¯æŒ .pdf å’Œ .txt")


def distill_with_gemini(text: str, api_key: str, num_pairs: int = 10, rotator: Optional[APIKeyRotator] = None) -> List[Dict]:
    """
    ä½¿ç”¨Gemini APIè¿›è¡ŒçŸ¥è¯†è’¸é¦

    Args:
        text: è¾“å…¥æ–‡æœ¬
        api_key: Gemini APIå¯†é’¥ï¼ˆå¦‚æœæä¾›rotatoråˆ™å¿½ç•¥æ­¤å‚æ•°ï¼‰
        num_pairs: ç”Ÿæˆçš„å¯¹è¯å¯¹æ•°é‡ï¼ˆé»˜è®¤10ç»„ï¼‰
        rotator: APIå¯†é’¥è½®æ¢å™¨ï¼ˆå¯é€‰ï¼‰

    Returns:
        å¯¹è¯å¯¹åˆ—è¡¨ï¼Œæ ¼å¼: [{"instruction": "...", "input": "", "output": "..."}]

    Raises:
        Exception: APIè°ƒç”¨å¤±è´¥
    """
    # å¦‚æœæä¾›äº†è½®æ¢å™¨ï¼Œä½¿ç”¨è½®æ¢å™¨çš„å¯†é’¥
    if rotator:
        api_key = rotator.get_current_key()

    # é…ç½®Geminiå®¢æˆ·ç«¯
    client = genai.Client(api_key=api_key)

    # System Prompt - é¢†åŸŸä¸“å®¶è§’è‰²
    system_prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„é¢†åŸŸçŸ¥è¯†ä¸“å®¶å’Œæ•™å­¦è®¾è®¡å¸ˆã€‚ä½ çš„ä»»åŠ¡æ˜¯ä»ç»™å®šçš„æ–‡æœ¬ä¸­æå–æ ¸å¿ƒçŸ¥è¯†ç‚¹ï¼Œå¹¶ç”Ÿæˆé«˜è´¨é‡çš„é—®ç­”å¯¹è¯å¯¹ï¼Œç”¨äºè®­ç»ƒå°å‹è¯­è¨€æ¨¡å‹ã€‚

è¦æ±‚ï¼š
1. ä»”ç»†é˜…è¯»å¹¶ç†è§£è¾“å…¥æ–‡æœ¬çš„æ ¸å¿ƒå†…å®¹
2. æå–è‡³å°‘ {num_pairs} ç»„æœ‰ä»·å€¼çš„çŸ¥è¯†ç‚¹
3. ä¸ºæ¯ä¸ªçŸ¥è¯†ç‚¹ç”Ÿæˆä¸€ä¸ªè‡ªç„¶çš„é—®é¢˜ï¼ˆinstructionï¼‰å’Œè¯¦ç»†çš„å›ç­”ï¼ˆoutputï¼‰
4. é—®é¢˜åº”è¯¥å¤šæ ·åŒ–ï¼ŒåŒ…æ‹¬ï¼šæ¦‚å¿µè§£é‡Šã€æ“ä½œæ­¥éª¤ã€æœ€ä½³å®è·µã€å¸¸è§é—®é¢˜ç­‰
5. å›ç­”åº”è¯¥å‡†ç¡®ã€è¯¦ç»†ã€ä¸“ä¸šï¼ŒåŸºäºæ–‡æœ¬å†…å®¹
6. inputå­—æ®µä¿æŒä¸ºç©ºå­—ç¬¦ä¸²

è¾“å‡ºæ ¼å¼ï¼ˆä¸¥æ ¼çš„JSONæ•°ç»„ï¼‰ï¼š
[
  {{
    "instruction": "é—®é¢˜å†…å®¹",
    "input": "",
    "output": "è¯¦ç»†çš„å›ç­”å†…å®¹"
  }}
]

ç°åœ¨è¯·å¤„ç†ä»¥ä¸‹æ–‡æœ¬ï¼š

{text}
"""

    try:
        # è°ƒç”¨Gemini API
        response = client.models.generate_content(
            model='gemini-2.5-flash',
            contents=system_prompt,
            config=types.GenerateContentConfig(
                temperature=0.7,
                top_p=0.95,
                top_k=40,
                max_output_tokens=8192,
                response_mime_type="application/json"
            )
        )

        # è§£æJSONå“åº”
        response_text = response.text.strip()

        # å¦‚æœå“åº”è¢«æˆªæ–­ï¼Œå°è¯•ä¿®å¤
        if not response_text.endswith(']'):
            # æ‰¾åˆ°æœ€åä¸€ä¸ªå®Œæ•´çš„å¯¹è±¡
            last_complete = response_text.rfind('},')
            if last_complete > 0:
                response_text = response_text[:last_complete+1] + '\n]'

        result = json.loads(response_text)

        # éªŒè¯æ ¼å¼
        if not isinstance(result, list):
            raise ValueError("Geminiè¿”å›çš„ä¸æ˜¯JSONæ•°ç»„æ ¼å¼")

        # éªŒè¯æ¯ä¸ªå¯¹è¯å¯¹çš„æ ¼å¼
        for item in result:
            if not all(key in item for key in ["instruction", "input", "output"]):
                raise ValueError("å¯¹è¯å¯¹ç¼ºå°‘å¿…éœ€å­—æ®µ: instruction, input, output")

        # æ ‡è®°æˆåŠŸ
        if rotator:
            rotator.mark_success()

        return result

    except json.JSONDecodeError as e:
        if rotator:
            rotator.mark_error(f"JSONè§£æå¤±è´¥: {e}")
        raise Exception(f"è§£æGeminiå“åº”å¤±è´¥: {e}\nå“åº”å†…å®¹: {response.text}")
    except Exception as e:
        error_msg = str(e).lower()

        # æ£€æŸ¥æ˜¯å¦æ˜¯é…é¢é”™è¯¯
        if "quota" in error_msg or "resource_exhausted" in error_msg or "429" in error_msg:
            if rotator:
                print(f"æ£€æµ‹åˆ°é…é¢é”™è¯¯ï¼Œå°è¯•åˆ‡æ¢APIå¯†é’¥...")
                try:
                    new_key = rotator.mark_quota_exceeded()
                    # é€’å½’é‡è¯•ï¼Œä½¿ç”¨æ–°å¯†é’¥
                    return distill_with_gemini(text, new_key, num_pairs, rotator)
                except RuntimeError as re:
                    raise Exception(f"æ‰€æœ‰APIå¯†é’¥é…é¢å·²ç”¨å®Œ: {re}")
            else:
                raise Exception(f"APIé…é¢å·²ç”¨å®Œ: {e}")
        # æ£€æŸ¥æ˜¯å¦æ˜¯ä¸Šä¸‹æ–‡è¿‡é•¿é”™è¯¯
        elif "context" in error_msg and ("too long" in error_msg or "length" in error_msg or "exceed" in error_msg):
            print(f"âš ï¸ æ£€æµ‹åˆ°ä¸Šä¸‹æ–‡è¿‡é•¿é”™è¯¯ï¼Œå°†åˆ‡æ¢åˆ°æ™ºè°±AIå¤„ç†...")
            raise Exception(f"CONTEXT_TOO_LONG: {e}")
        else:
            if rotator:
                rotator.mark_error(str(e))
            raise Exception(f"Gemini APIè°ƒç”¨å¤±è´¥: {e}")


def split_text_into_chunks(text: str, chunk_size: int = 15000, overlap: int = 500) -> List[str]:
    """
    å°†é•¿æ–‡æœ¬åˆ†å‰²æˆå¤šä¸ªå—ï¼Œç”¨äºå¤„ç†è¶…é•¿æ–‡æ¡£

    Args:
        text: è¾“å…¥æ–‡æœ¬
        chunk_size: æ¯å—çš„å­—ç¬¦æ•°ï¼ˆé»˜è®¤15000å­—ç¬¦ï¼Œçº¦10-15é¡µï¼‰
        overlap: å—ä¹‹é—´çš„é‡å å­—ç¬¦æ•°ï¼ˆé»˜è®¤500ï¼Œé¿å…çŸ¥è¯†ç‚¹è¢«æˆªæ–­ï¼‰

    Returns:
        æ–‡æœ¬å—åˆ—è¡¨
    """
    if len(text) <= chunk_size:
        return [text]

    chunks = []
    start = 0

    while start < len(text):
        end = start + chunk_size

        # å¦‚æœä¸æ˜¯æœ€åä¸€å—ï¼Œå°è¯•åœ¨å¥å·ã€é—®å·ã€æ„Ÿå¹å·å¤„åˆ†å‰²
        if end < len(text):
            # åœ¨chunk_sizeé™„è¿‘å¯»æ‰¾åˆé€‚çš„åˆ†å‰²ç‚¹
            search_start = max(start + chunk_size - 200, start)
            search_end = min(start + chunk_size + 200, len(text))
            search_text = text[search_start:search_end]

            # å¯»æ‰¾å¥å­ç»“æŸæ ‡è®°
            for delimiter in ['ã€‚\n', 'ã€‚', 'ï¼', 'ï¼Ÿ', '\n\n']:
                pos = search_text.rfind(delimiter)
                if pos != -1:
                    end = search_start + pos + len(delimiter)
                    break

        chunk = text[start:end].strip()
        if chunk:
            chunks.append(chunk)

        # ä¸‹ä¸€å—ä»å½“å‰å—ç»“æŸå‰overlapä¸ªå­—ç¬¦å¼€å§‹
        start = end - overlap if end < len(text) else end

    return chunks


def save_as_jsonl(data: List[Dict], output_path: str) -> str:
    """
    å°†æ•°æ®ä¿å­˜ä¸ºJSONLæ ¼å¼

    Args:
        data: å¯¹è¯å¯¹åˆ—è¡¨
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•ï¼‰

    Returns:
        ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
    """
    # ç¡®ä¿ä½¿ç”¨ç›¸å¯¹è·¯å¾„
    output_path = Path(output_path)

    # åˆ›å»ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    output_path.parent.mkdir(parents=True, exist_ok=True)

    # å†™å…¥JSONLæ ¼å¼
    with open(output_path, 'w', encoding='utf-8') as f:
        for item in data:
            json_line = json.dumps(item, ensure_ascii=False)
            f.write(json_line + '\n')

    return str(output_path)


class DataDistiller:
    """æ•°æ®è’¸é¦å™¨ - å®Œæ•´çš„è’¸é¦æµç¨‹"""

    def __init__(self, api_key: str = None, api_keys: List[str] = None, use_rotation: bool = True, zhipu_api_key: str = None):
        """
        åˆå§‹åŒ–æ•°æ®è’¸é¦å™¨

        Args:
            api_key: å•ä¸ªGemini APIå¯†é’¥ï¼ˆå¦‚æœä¸ä½¿ç”¨è½®æ¢ï¼‰
            api_keys: å¤šä¸ªAPIå¯†é’¥åˆ—è¡¨ï¼ˆç”¨äºè½®æ¢ï¼‰
            use_rotation: æ˜¯å¦ä½¿ç”¨å¯†é’¥è½®æ¢ï¼ˆé»˜è®¤Trueï¼‰
            zhipu_api_key: æ™ºè°±AI APIå¯†é’¥ï¼ˆç”¨äºå¤„ç†ä¸Šä¸‹æ–‡è¿‡é•¿çš„æƒ…å†µï¼‰
        """
        self.use_rotation = use_rotation
        self.zhipu_api_key = zhipu_api_key or "0608bfac12ae33755667214aa6d00657.oljJQXnYGuGGF6pf"

        if use_rotation:
            if api_keys:
                self.rotator = APIKeyRotator(api_keys, cooldown_minutes=60)
            else:
                # ä½¿ç”¨é»˜è®¤å¯†é’¥åˆ—è¡¨
                from utils.api_key_rotator import create_default_rotator
                self.rotator = create_default_rotator(cooldown_minutes=60)
                print(f"ä½¿ç”¨é»˜è®¤APIå¯†é’¥æ± ï¼Œå…± {len(self.rotator.api_keys)} ä¸ªå¯†é’¥")
            self.api_key = None
        else:
            if not api_key:
                raise ValueError("æœªå¯ç”¨è½®æ¢æ—¶å¿…é¡»æä¾›api_keyå‚æ•°")
            self.api_key = api_key
            self.rotator = None

    def process_file(
        self,
        file_path: str,
        output_dir: str = "data",
        num_pairs: int = 10
    ) -> str:
        """
        å¤„ç†å•ä¸ªæ–‡ä»¶çš„å®Œæ•´è’¸é¦æµç¨‹

        Args:
            file_path: è¾“å…¥æ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤data/ï¼‰
            num_pairs: ç”Ÿæˆçš„å¯¹è¯å¯¹æ•°é‡

        Returns:
            è¾“å‡ºJSONLæ–‡ä»¶è·¯å¾„
        """
        # 1. æå–æ–‡æœ¬
        print(f"æ­£åœ¨æå–æ–‡æœ¬: {file_path}")
        text = extract_text(file_path)
        print(f"æå–å®Œæˆï¼Œæ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦")

        # 2. çŸ¥è¯†è’¸é¦
        print(f"æ­£åœ¨ä½¿ç”¨Geminiè¿›è¡ŒçŸ¥è¯†è’¸é¦...")
        try:
            if self.use_rotation:
                distilled_data = distill_with_gemini(text, None, num_pairs, self.rotator)
            else:
                distilled_data = distill_with_gemini(text, self.api_key, num_pairs)
            print(f"è’¸é¦å®Œæˆï¼Œç”Ÿæˆ {len(distilled_data)} ç»„å¯¹è¯å¯¹")
        except Exception as e:
            # æ£€æŸ¥æ˜¯å¦æ˜¯ä¸Šä¸‹æ–‡è¿‡é•¿é”™è¯¯
            if "CONTEXT_TOO_LONG" in str(e):
                print(f"âš ï¸ Geminiä¸Šä¸‹æ–‡è¿‡é•¿ï¼Œåˆ‡æ¢åˆ°æ™ºè°±AI...")
                from utils.zhipu_client import distill_with_zhipu
                distilled_data = distill_with_zhipu(text, self.zhipu_api_key, num_pairs)
                print(f"âœ… æ™ºè°±AIè’¸é¦å®Œæˆï¼Œç”Ÿæˆ {len(distilled_data)} ç»„å¯¹è¯å¯¹")
            else:
                raise

        # 3. ä¿å­˜ä¸ºJSONL
        input_filename = Path(file_path).stem
        output_path = Path(output_dir) / f"{input_filename}_distilled.jsonl"
        saved_path = save_as_jsonl(distilled_data, str(output_path))
        print(f"å·²ä¿å­˜åˆ°: {saved_path}")

        return saved_path

    def process_file_chunked(
        self,
        file_path: str,
        output_dir: str = "data",
        num_pairs_per_chunk: int = 30,
        chunk_size: int = 15000,
        overlap: int = 500
    ) -> str:
        """
        åˆ†å—å¤„ç†å¤§æ–‡ä»¶çš„å®Œæ•´è’¸é¦æµç¨‹ï¼ˆé€‚ç”¨äº100+é¡µçš„é•¿æ–‡æ¡£ï¼‰

        Args:
            file_path: è¾“å…¥æ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤data/ï¼‰
            num_pairs_per_chunk: æ¯ä¸ªå—ç”Ÿæˆçš„å¯¹è¯å¯¹æ•°é‡ï¼ˆé»˜è®¤30ï¼‰
            chunk_size: æ¯å—çš„å­—ç¬¦æ•°ï¼ˆé»˜è®¤15000å­—ç¬¦ï¼Œçº¦10-15é¡µï¼‰
            overlap: å—ä¹‹é—´çš„é‡å å­—ç¬¦æ•°ï¼ˆé»˜è®¤500ï¼‰

        Returns:
            è¾“å‡ºJSONLæ–‡ä»¶è·¯å¾„
        """
        # 1. æå–æ–‡æœ¬
        print(f"ğŸ“„ æ­£åœ¨æå–æ–‡æœ¬: {file_path}")
        text = extract_text(file_path)
        print(f"âœ… æå–å®Œæˆï¼Œæ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦")

        # 2. åˆ†å—
        print(f"âœ‚ï¸  æ­£åœ¨åˆ†å‰²æ–‡æœ¬...")
        chunks = split_text_into_chunks(text, chunk_size=chunk_size, overlap=overlap)
        print(f"âœ… åˆ†å‰²å®Œæˆï¼Œå…± {len(chunks)} ä¸ªå—")
        print(f"   é¢„è®¡ç”Ÿæˆ {len(chunks) * num_pairs_per_chunk} ç»„å¯¹è¯å¯¹")

        # 3. é€å—è’¸é¦
        all_distilled_data = []
        for i, chunk in enumerate(chunks, 1):
            print(f"\nğŸ”„ å¤„ç†ç¬¬ {i}/{len(chunks)} å— (é•¿åº¦: {len(chunk)} å­—ç¬¦)...")

            try:
                if self.use_rotation:
                    chunk_data = distill_with_gemini(chunk, None, num_pairs_per_chunk, self.rotator)
                else:
                    chunk_data = distill_with_gemini(chunk, self.api_key, num_pairs_per_chunk)

                print(f"   âœ… ç¬¬ {i} å—å®Œæˆï¼Œç”Ÿæˆ {len(chunk_data)} ç»„å¯¹è¯å¯¹")
                all_distilled_data.extend(chunk_data)

            except Exception as e:
                # æ£€æŸ¥æ˜¯å¦æ˜¯ä¸Šä¸‹æ–‡è¿‡é•¿é”™è¯¯
                if "CONTEXT_TOO_LONG" in str(e):
                    print(f"   âš ï¸ Geminiä¸Šä¸‹æ–‡è¿‡é•¿ï¼Œåˆ‡æ¢åˆ°æ™ºè°±AI...")
                    try:
                        from utils.zhipu_client import distill_with_zhipu
                        chunk_data = distill_with_zhipu(chunk, self.zhipu_api_key, num_pairs_per_chunk)
                        print(f"   âœ… æ™ºè°±AIå¤„ç†å®Œæˆï¼Œç”Ÿæˆ {len(chunk_data)} ç»„å¯¹è¯å¯¹")
                        all_distilled_data.extend(chunk_data)
                    except Exception as zhipu_error:
                        print(f"   âŒ ç¬¬ {i} å—å¤„ç†å¤±è´¥: {zhipu_error}")
                        continue
                else:
                    print(f"   âŒ ç¬¬ {i} å—å¤„ç†å¤±è´¥: {e}")
                    continue

        # 4. ä¿å­˜ä¸ºJSONL
        print(f"\nğŸ’¾ æ­£åœ¨ä¿å­˜ç»“æœ...")
        input_filename = Path(file_path).stem
        output_path = Path(output_dir) / f"{input_filename}_distilled_chunked.jsonl"
        saved_path = save_as_jsonl(all_distilled_data, str(output_path))

        print(f"\n{'='*60}")
        print(f"âœ… è’¸é¦å®Œæˆï¼")
        print(f"   æ–‡ä»¶: {file_path}")
        print(f"   è¾“å‡º: {saved_path}")
        print(f"   æ€»å—æ•°: {len(chunks)}")
        print(f"   ç”Ÿæˆå¯¹è¯å¯¹: {len(all_distilled_data)} ç»„")
        print(f"{'='*60}")

        return saved_path

    def process_directory(
        self,
        input_dir: str,
        output_dir: str = "data",
        num_pairs: int = 10
    ) -> List[str]:
        """
        æ‰¹é‡å¤„ç†ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶

        Args:
            input_dir: è¾“å…¥ç›®å½•
            output_dir: è¾“å‡ºç›®å½•
            num_pairs: æ¯ä¸ªæ–‡ä»¶ç”Ÿæˆçš„å¯¹è¯å¯¹æ•°é‡

        Returns:
            æ‰€æœ‰è¾“å‡ºæ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        input_path = Path(input_dir)
        output_paths = []

        # æ”¯æŒçš„æ–‡ä»¶æ ¼å¼
        supported_extensions = ['.pdf', '.txt']

        # éå†ç›®å½•
        for file_path in input_path.iterdir():
            if file_path.is_file() and file_path.suffix.lower() in supported_extensions:
                try:
                    output_path = self.process_file(
                        str(file_path),
                        output_dir,
                        num_pairs
                    )
                    output_paths.append(output_path)
                except Exception as e:
                    print(f"å¤„ç†æ–‡ä»¶ {file_path} å¤±è´¥: {e}")
                    continue

        return output_paths

    def get_status_report(self) -> str:
        """
        è·å–APIå¯†é’¥ä½¿ç”¨çŠ¶æ€æŠ¥å‘Š

        Returns:
            çŠ¶æ€æŠ¥å‘Šå­—ç¬¦ä¸²
        """
        if self.use_rotation and self.rotator:
            return self.rotator.get_status_report()
        else:
            return "æœªå¯ç”¨å¯†é’¥è½®æ¢"


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # ç¤ºä¾‹1ï¼šä½¿ç”¨é»˜è®¤å¯†é’¥æ± ï¼ˆè‡ªåŠ¨è½®æ¢ï¼‰
    print("=== ç¤ºä¾‹1: ä½¿ç”¨é»˜è®¤å¯†é’¥æ±  ===")
    distiller = DataDistiller()  # è‡ªåŠ¨ä½¿ç”¨é»˜è®¤çš„9ä¸ªAPIå¯†é’¥

    # å¤„ç†å•ä¸ªæ–‡ä»¶
    output_file = distiller.process_file(
        file_path="data/example.pdf",
        output_dir="data",
        num_pairs=15
    )
    print(f"è’¸é¦å®Œæˆ: {output_file}")

    # æŸ¥çœ‹å¯†é’¥ä½¿ç”¨çŠ¶æ€
    print(distiller.get_status_report())

    # ç¤ºä¾‹2ï¼šä½¿ç”¨è‡ªå®šä¹‰å¯†é’¥åˆ—è¡¨
    print("\n=== ç¤ºä¾‹2: ä½¿ç”¨è‡ªå®šä¹‰å¯†é’¥åˆ—è¡¨ ===")
    custom_keys = [
        "YOUR_API_KEY_1",
        "YOUR_API_KEY_2",
        "YOUR_API_KEY_3"
    ]
    distiller2 = DataDistiller(api_keys=custom_keys, use_rotation=True)

    # ç¤ºä¾‹3ï¼šä¸ä½¿ç”¨è½®æ¢ï¼ˆå•ä¸ªå¯†é’¥ï¼‰
    print("\n=== ç¤ºä¾‹3: å•ä¸ªå¯†é’¥æ¨¡å¼ ===")
    distiller3 = DataDistiller(api_key="YOUR_SINGLE_API_KEY", use_rotation=False)

    # å¤„ç†å•ä¸ªæ–‡ä»¶
    output_file = distiller.process_file(
        file_path="data/example.pdf",
        output_dir="data",
        num_pairs=15
    )
    print(f"è’¸é¦å®Œæˆ: {output_file}")
