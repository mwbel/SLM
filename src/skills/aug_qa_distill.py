"""
DataDistillerSkill - æ•°æ®è’¸é¦å™¨

è´Ÿè´£ï¼š
1. å°† Markdown æ–‡æœ¬è½¬åŒ–ä¸ºé«˜è´¨é‡çš„ Question-Answer å¯¹
2. é›†æˆ Gemini 2.0 æˆ– DeepSeek API
3. æ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼ˆå¤„ç†ä¸­æ–­åå¯ç»§ç»­ï¼‰
4. è‡ªåŠ¨è¿½åŠ ä¿å­˜åˆ° JSONL æ–‡ä»¶
"""

import asyncio
import json
import os
from pathlib import Path
from typing import Dict, Any, List, Optional
from datetime import datetime
from .base_skill import BaseSkill
from .api_manager import APIManagerSkill


class DataDistillerSkill(BaseSkill):
    """
    æ•°æ®è’¸é¦ Skill

    å°†æ–‡æ¡£å†…å®¹è½¬åŒ–ä¸ºé«˜è´¨é‡çš„ QA å¯¹ï¼Œç”¨äºè®­ç»ƒå°æ¨¡å‹
    """

    # è´¢åŠ¡æŠ¥é”€åˆ¶åº¦ä¸“ä¸š Prompt æ¨¡æ¿
    SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„è´¢åŠ¡ç®¡ç†ä¸“å®¶ï¼Œä¸“é—¨è´Ÿè´£ä¼ä¸šè´¢åŠ¡æŠ¥é”€åˆ¶åº¦çš„åŸ¹è®­å’Œå’¨è¯¢å·¥ä½œã€‚ä½ æ‹¥æœ‰è¶…è¿‡15å¹´çš„è´¢åŠ¡ç®¡ç†ç»éªŒï¼Œç²¾é€šå„ç±»ä¼ä¸šçš„æŠ¥é”€æµç¨‹ã€è´¢åŠ¡åˆè§„è¦æ±‚å’Œå®¡è®¡æ ‡å‡†ã€‚

ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®æä¾›çš„è´¢åŠ¡æŠ¥é”€åˆ¶åº¦æ–‡æ¡£ï¼Œç”Ÿæˆé«˜è´¨é‡çš„é—®ç­”å¯¹ï¼Œç”¨äºåŸ¹è®­ä¼ä¸šå‘˜å·¥å’Œè´¢åŠ¡äººå‘˜ã€‚

è¦æ±‚ï¼š
1. é—®é¢˜å¿…é¡»å…·ä½“ã€å®ç”¨ï¼Œæ¶µç›–å‘˜å·¥åœ¨å®é™…æŠ¥é”€è¿‡ç¨‹ä¸­å¯èƒ½é‡åˆ°çš„åœºæ™¯
2. ç­”æ¡ˆå¿…é¡»å‡†ç¡®ã€ä¸“ä¸šï¼Œä¸¥æ ¼åŸºäºæ–‡æ¡£å†…å®¹ï¼Œä¸å¾—ç¼–é€ æˆ–æ¨æµ‹
3. ç­”æ¡ˆè¦åŒ…å«å…·ä½“çš„é‡‘é¢ã€æ—¶é™ã€æµç¨‹æ­¥éª¤ç­‰å…³é”®ä¿¡æ¯
4. å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰æ˜ç¡®è¯´æ˜ï¼Œç­”æ¡ˆä¸­è¦è¯šå®åœ°æŒ‡å‡º"æ–‡æ¡£æœªæ˜ç¡®è§„å®š"
5. ä½¿ç”¨æ¸…æ™°ã€æ˜“æ‡‚çš„è¯­è¨€ï¼Œé¿å…è¿‡äºå¤æ‚çš„è´¢åŠ¡æœ¯è¯­
6. æ¯ä¸ªé—®ç­”å¯¹è¦ç‹¬ç«‹å®Œæ•´ï¼Œä¸ä¾èµ–ä¸Šä¸‹æ–‡

ç”Ÿæˆçš„é—®ç­”å¯¹å°†ç”¨äºè®­ç»ƒAIåŠ©æ‰‹ï¼Œå¸®åŠ©å‘˜å·¥å¿«é€Ÿäº†è§£æŠ¥é”€åˆ¶åº¦ã€‚"""

    USER_PROMPT_TEMPLATE = """è¯·æ ¹æ®ä»¥ä¸‹è´¢åŠ¡æŠ¥é”€åˆ¶åº¦æ–‡æ¡£å†…å®¹ï¼Œç”Ÿæˆ {num_qa} ä¸ªé«˜è´¨é‡çš„é—®ç­”å¯¹ã€‚

æ–‡æ¡£å†…å®¹ï¼š
```
{content}
```

è¦æ±‚ï¼š
1. é—®é¢˜ç±»å‹è¦å¤šæ ·åŒ–ï¼šåŒ…æ‹¬"å¦‚ä½•åŠç†"ã€"éœ€è¦ä»€ä¹ˆææ–™"ã€"é‡‘é¢é™åˆ¶"ã€"å®¡æ‰¹æµç¨‹"ã€"æ—¶é—´è¦æ±‚"ç­‰
2. è¦†ç›–æ–‡æ¡£ä¸­çš„å…³é”®ä¿¡æ¯ç‚¹
3. é—®é¢˜è¦è‡ªç„¶ï¼ŒåƒçœŸå®å‘˜å·¥ä¼šé—®çš„é‚£æ ·
4. ç­”æ¡ˆè¦å‡†ç¡®ã€å®Œæ•´ï¼ŒåŒ…å«æ‰€æœ‰å¿…è¦çš„ç»†èŠ‚

è¯·ä»¥ JSON æ ¼å¼è¿”å›ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
```json
[
    {{
        "question": "å…·ä½“çš„é—®é¢˜",
        "answer": "è¯¦ç»†çš„ç­”æ¡ˆ"
    }},
    ...
]
```

åªè¿”å› JSON æ•°ç»„ï¼Œä¸è¦åŒ…å«å…¶ä»–å†…å®¹ã€‚"""

    def __init__(self,
                 api_manager: Optional[APIManagerSkill] = None,
                 api_provider: str = 'gemini',
                 api_config_file: Optional[str] = None,
                 output_file: str = 'data/output/dataset.jsonl',
                 checkpoint_dir: str = '.checkpoints',
                 chunk_size: int = 2000,
                 qa_per_chunk: int = 5,
                 max_retries: int = 3):
        """
        åˆå§‹åŒ– DataDistillerSkill

        Args:
            api_manager: APIManagerSkill å®ä¾‹ï¼ˆå¦‚æœä¸º Noneï¼Œè‡ªåŠ¨åˆ›å»ºï¼‰
            api_provider: API æä¾›å•† ('gemini', 'deepseek', 'openai')
            api_config_file: API é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            output_file: è¾“å‡º JSONL æ–‡ä»¶è·¯å¾„
            checkpoint_dir: æ–­ç‚¹æ–‡ä»¶ä¿å­˜ç›®å½•
            chunk_size: æ–‡æœ¬åˆ‡ç‰‡å¤§å°ï¼ˆå­—ç¬¦æ•°ï¼‰
            qa_per_chunk: æ¯ä¸ªåˆ‡ç‰‡ç”Ÿæˆçš„ QA å¯¹æ•°é‡
            max_retries: API è°ƒç”¨å¤±è´¥æ—¶çš„æœ€å¤§é‡è¯•æ¬¡æ•°
        """
        super().__init__(name="DataDistiller")

        self.api_provider = api_provider.lower()
        self.chunk_size = chunk_size
        self.qa_per_chunk = qa_per_chunk
        self.max_retries = max_retries

        # è®¾ç½®è¾“å‡ºæ–‡ä»¶
        self.output_file = Path(output_file)
        self.output_file.parent.mkdir(parents=True, exist_ok=True)

        # è®¾ç½®æ–­ç‚¹ç›®å½•
        self.checkpoint_dir = Path(checkpoint_dir)
        self.checkpoint_dir.mkdir(parents=True, exist_ok=True)

        # åˆå§‹åŒ–æˆ–ä½¿ç”¨æä¾›çš„ API ç®¡ç†å™¨
        if api_manager:
            self.api_manager = api_manager
            self.logger.info("âœ… ä½¿ç”¨æä¾›çš„ API ç®¡ç†å™¨")
        else:
            self.api_manager = APIManagerSkill(
                config_file=api_config_file,
                auto_rotate=True,
                failure_threshold=3,
                cooldown_minutes=5
            )
            self.logger.info("âœ… åˆ›å»ºæ–°çš„ API ç®¡ç†å™¨")

        # å½“å‰ä½¿ç”¨çš„ API é…ç½®
        self.current_api = None
        self.current_client = None

    def _get_api_client(self):
        """
        è·å– API å®¢æˆ·ç«¯ï¼ˆé€šè¿‡ API ç®¡ç†å™¨ï¼‰

        Returns:
            (client, api_config) å…ƒç»„
        """
        # ä» API ç®¡ç†å™¨è·å–å¯ç”¨ API
        api_config = self.api_manager.get_available_api(self.api_provider)

        if not api_config:
            raise RuntimeError(f"æ²¡æœ‰å¯ç”¨çš„ {self.api_provider} API")

        # å¦‚æœ API é…ç½®æ”¹å˜ï¼Œé‡æ–°åˆå§‹åŒ–å®¢æˆ·ç«¯
        if not self.current_api or self.current_api['api_id'] != api_config['api_id']:
            self.current_api = api_config
            self.current_client = self._init_client(api_config)
            self.logger.info(f"ğŸ”„ åˆ‡æ¢åˆ° API: {api_config.get('name', api_config['api_id'])}")

        return self.current_client, self.current_api

    def _init_client(self, api_config: Dict[str, Any]):
        """
        åˆå§‹åŒ– API å®¢æˆ·ç«¯

        Args:
            api_config: API é…ç½®å­—å…¸

        Returns:
            åˆå§‹åŒ–çš„å®¢æˆ·ç«¯
        """
        api_key = api_config['api_key']
        model_name = api_config['model']

        if self.api_provider == 'gemini':
            try:
                import google.generativeai as genai
                genai.configure(api_key=api_key)
                client = genai.GenerativeModel(model_name)
                self.logger.info(f"âœ… Gemini å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸï¼Œæ¨¡å‹: {model_name}")
                return client
            except ImportError:
                raise ImportError(
                    "éœ€è¦å®‰è£… google-generativeai åº“\n"
                    "å®‰è£…æ–¹æ³•: pip install google-generativeai"
                )

        elif self.api_provider == 'deepseek':
            try:
                from openai import OpenAI
                client = OpenAI(
                    api_key=api_key,
                    base_url="https://api.deepseek.com"
                )
                self.logger.info(f"âœ… DeepSeek å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸï¼Œæ¨¡å‹: {model_name}")
                return client
            except ImportError:
                raise ImportError(
                    "éœ€è¦å®‰è£… openai åº“\n"
                    "å®‰è£…æ–¹æ³•: pip install openai"
                )

        elif self.api_provider == 'openai':
            try:
                from openai import OpenAI
                client = OpenAI(api_key=api_key)
                self.logger.info(f"âœ… OpenAI å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸï¼Œæ¨¡å‹: {model_name}")
                return client
            except ImportError:
                raise ImportError(
                    "éœ€è¦å®‰è£… openai åº“\n"
                    "å®‰è£…æ–¹æ³•: pip install openai"
                )
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„ API æä¾›å•†: {self.api_provider}")

    async def execute(self, input_data: Any, **kwargs) -> Dict[str, Any]:
        """
        æ‰§è¡Œæ•°æ®è’¸é¦

        Args:
            input_data: è¾“å…¥æ•°æ®ï¼Œå¯ä»¥æ˜¯ï¼š
                - str: Markdown æ–‡æœ¬å†…å®¹
                - dict: åŒ…å« 'content' å­—æ®µçš„å­—å…¸ï¼ˆparser_pdf_ocr çš„è¾“å‡ºï¼‰
            **kwargs: é¢å¤–å‚æ•°
                - resume: bool, æ˜¯å¦ä»æ–­ç‚¹æ¢å¤ï¼ˆé»˜è®¤ Trueï¼‰
                - source_file: str, æºæ–‡ä»¶åï¼ˆç”¨äºæ–­ç‚¹æ ‡è¯†ï¼‰

        Returns:
            {
                'total_qa_pairs': int,      # ç”Ÿæˆçš„ QA å¯¹æ€»æ•°
                'output_file': str,          # è¾“å‡ºæ–‡ä»¶è·¯å¾„
                'chunks_processed': int,     # å¤„ç†çš„æ–‡æœ¬å—æ•°
                'api_calls': int,            # API è°ƒç”¨æ¬¡æ•°
                'failed_chunks': int         # å¤±è´¥çš„æ–‡æœ¬å—æ•°
            }
        """
        # è§£æè¾“å…¥æ•°æ®
        if isinstance(input_data, dict):
            content = input_data.get('content', '')
            source_file = input_data.get('file_path', 'unknown')
        else:
            content = str(input_data)
            source_file = kwargs.get('source_file', 'unknown')

        if not content:
            raise ValueError("è¾“å…¥å†…å®¹ä¸ºç©º")

        resume = kwargs.get('resume', True)

        self.logger.info(f"ğŸ“ å¼€å§‹æ•°æ®è’¸é¦")
        self.logger.info(f"   å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
        self.logger.info(f"   åˆ‡ç‰‡å¤§å°: {self.chunk_size} å­—ç¬¦")
        self.logger.info(f"   æ¯ç‰‡ç”Ÿæˆ: {self.qa_per_chunk} ä¸ª QA å¯¹")

        # åˆ‡åˆ†æ–‡æœ¬
        chunks = self._split_content(content)
        self.logger.info(f"   åˆ‡åˆ†ä¸º {len(chunks)} ä¸ªæ–‡æœ¬å—")

        # æ£€æŸ¥æ–­ç‚¹
        checkpoint_file = self.checkpoint_dir / f"{Path(source_file).stem}_distill_checkpoint.json"
        start_chunk = 0

        if resume and checkpoint_file.exists():
            checkpoint = self._load_checkpoint(checkpoint_file)
            start_chunk = checkpoint.get('last_processed_chunk', 0) + 1
            self.logger.info(f"ğŸ”„ ä»æ–­ç‚¹æ¢å¤ï¼Œèµ·å§‹å—: {start_chunk + 1}/{len(chunks)}")

        # å¤„ç†æ¯ä¸ªæ–‡æœ¬å—
        total_qa_pairs = 0
        api_calls = 0
        failed_chunks = 0

        for i in range(start_chunk, len(chunks)):
            chunk = chunks[i]
            self.logger.info(f"\nğŸ”„ å¤„ç†æ–‡æœ¬å— {i + 1}/{len(chunks)}")

            try:
                # è°ƒç”¨ API ç”Ÿæˆ QA å¯¹
                qa_pairs = await self._generate_qa_pairs(chunk, self.qa_per_chunk)
                api_calls += 1

                if qa_pairs:
                    # ä¿å­˜åˆ° JSONL æ–‡ä»¶
                    self._append_to_jsonl(qa_pairs)
                    total_qa_pairs += len(qa_pairs)
                    self.logger.info(f"   âœ… ç”Ÿæˆ {len(qa_pairs)} ä¸ª QA å¯¹")
                else:
                    failed_chunks += 1
                    self.logger.warning(f"   âš ï¸  æœªç”Ÿæˆ QA å¯¹")

                # ä¿å­˜æ–­ç‚¹
                self._save_checkpoint(checkpoint_file, {
                    'source_file': source_file,
                    'total_chunks': len(chunks),
                    'last_processed_chunk': i,
                    'total_qa_pairs': total_qa_pairs,
                    'timestamp': datetime.now().isoformat()
                })

            except Exception as e:
                failed_chunks += 1
                self.logger.error(f"   âŒ å¤„ç†å¤±è´¥: {e}")

                # ä¿å­˜æ–­ç‚¹ï¼ˆå¤±è´¥æ—¶ä¹Ÿä¿å­˜ï¼‰
                self._save_checkpoint(checkpoint_file, {
                    'source_file': source_file,
                    'total_chunks': len(chunks),
                    'last_processed_chunk': i - 1,  # å›é€€åˆ°ä¸Šä¸€ä¸ªæˆåŠŸçš„å—
                    'total_qa_pairs': total_qa_pairs,
                    'last_error': str(e),
                    'timestamp': datetime.now().isoformat()
                })

                # å¦‚æœå¤±è´¥æ¬¡æ•°è¿‡å¤šï¼ŒæŠ›å‡ºå¼‚å¸¸
                if failed_chunks > len(chunks) * 0.3:  # è¶…è¿‡ 30% å¤±è´¥
                    raise RuntimeError(f"å¤±è´¥ç‡è¿‡é«˜: {failed_chunks}/{i + 1}")

        # æ¸…ç†æ–­ç‚¹æ–‡ä»¶ï¼ˆå…¨éƒ¨å®Œæˆï¼‰
        if checkpoint_file.exists():
            checkpoint_file.unlink()
            self.logger.info("âœ… å¤„ç†å®Œæˆï¼Œå·²æ¸…ç†æ–­ç‚¹æ–‡ä»¶")

        return {
            'total_qa_pairs': total_qa_pairs,
            'output_file': str(self.output_file),
            'chunks_processed': len(chunks) - start_chunk,
            'api_calls': api_calls,
            'failed_chunks': failed_chunks
        }

    def _split_content(self, content: str) -> List[str]:
        """
        åˆ‡åˆ†æ–‡æœ¬å†…å®¹

        Args:
            content: æ–‡æœ¬å†…å®¹

        Returns:
            æ–‡æœ¬å—åˆ—è¡¨
        """
        chunks = []
        lines = content.split('\n')
        current_chunk = []
        current_size = 0

        for line in lines:
            line_size = len(line)

            # å¦‚æœå½“å‰å—åŠ ä¸Šè¿™ä¸€è¡Œä¼šè¶…è¿‡é™åˆ¶ï¼Œä¿å­˜å½“å‰å—
            if current_size + line_size > self.chunk_size and current_chunk:
                chunks.append('\n'.join(current_chunk))
                current_chunk = []
                current_size = 0

            current_chunk.append(line)
            current_size += line_size + 1  # +1 for newline

        # æ·»åŠ æœ€åä¸€ä¸ªå—
        if current_chunk:
            chunks.append('\n'.join(current_chunk))

        return chunks

    async def _generate_qa_pairs(self, content: str, num_qa: int) -> List[Dict[str, str]]:
        """
        è°ƒç”¨ API ç”Ÿæˆ QA å¯¹

        Args:
            content: æ–‡æœ¬å†…å®¹
            num_qa: è¦ç”Ÿæˆçš„ QA å¯¹æ•°é‡

        Returns:
            QA å¯¹åˆ—è¡¨
        """
        prompt = self.USER_PROMPT_TEMPLATE.format(
            content=content,
            num_qa=num_qa
        )

        for attempt in range(self.max_retries):
            try:
                # è·å– API å®¢æˆ·ç«¯
                client, api_config = self._get_api_client()
                api_id = api_config['api_id']

                # è°ƒç”¨ API
                if self.api_provider == 'gemini':
                    response = await self._call_gemini(client, prompt)
                elif self.api_provider == 'deepseek':
                    response = await self._call_deepseek(client, api_config['model'], prompt)
                elif self.api_provider == 'openai':
                    response = await self._call_openai(client, api_config['model'], prompt)
                else:
                    raise ValueError(f"ä¸æ”¯æŒçš„ API æä¾›å•†: {self.api_provider}")

                # è§£æ JSON å“åº”
                qa_pairs = self._parse_response(response)

                # æŠ¥å‘ŠæˆåŠŸ
                self.api_manager.report_success(api_id)

                return qa_pairs

            except Exception as e:
                # æŠ¥å‘Šå¤±è´¥
                if self.current_api:
                    self.api_manager.report_failure(self.current_api['api_id'], str(e))

                self.logger.warning(f"   API è°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}/{self.max_retries}): {e}")

                if attempt < self.max_retries - 1:
                    # é‡è¯•å‰ç­‰å¾…ï¼ˆæŒ‡æ•°é€€é¿ï¼‰
                    await asyncio.sleep(2 ** attempt)
                    # æ¸…é™¤å½“å‰ APIï¼Œä¸‹æ¬¡é‡è¯•æ—¶ä¼šè·å–æ–°çš„
                    self.current_api = None
                    self.current_client = None
                else:
                    raise

        return []

    async def _call_gemini(self, client, prompt: str) -> str:
        """è°ƒç”¨ Gemini API"""
        response = client.generate_content(
            [self.SYSTEM_PROMPT, prompt],
            generation_config={
                'temperature': 0.7,
                'top_p': 0.95,
                'max_output_tokens': 8192,
            }
        )
        return response.text

    async def _call_deepseek(self, client, model: str, prompt: str) -> str:
        """è°ƒç”¨ DeepSeek API"""
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": self.SYSTEM_PROMPT},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=8192
        )
        return response.choices[0].message.content

    async def _call_openai(self, client, model: str, prompt: str) -> str:
        """è°ƒç”¨ OpenAI API"""
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": self.SYSTEM_PROMPT},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=8192
        )
        return response.choices[0].message.content

    def _parse_response(self, response: str) -> List[Dict[str, str]]:
        """
        è§£æ API å“åº”ï¼Œæå– QA å¯¹

        Args:
            response: API å“åº”æ–‡æœ¬

        Returns:
            QA å¯¹åˆ—è¡¨
        """
        # å°è¯•æå– JSON
        import re

        # æŸ¥æ‰¾ JSON æ•°ç»„
        json_match = re.search(r'\[[\s\S]*\]', response)
        if json_match:
            json_str = json_match.group(0)
            try:
                qa_pairs = json.loads(json_str)

                # éªŒè¯æ ¼å¼
                if isinstance(qa_pairs, list):
                    valid_pairs = []
                    for pair in qa_pairs:
                        if isinstance(pair, dict) and 'question' in pair and 'answer' in pair:
                            valid_pairs.append({
                                'question': pair['question'].strip(),
                                'answer': pair['answer'].strip()
                            })
                    return valid_pairs
            except json.JSONDecodeError as e:
                self.logger.error(f"JSON è§£æå¤±è´¥: {e}")

        return []

    def _append_to_jsonl(self, qa_pairs: List[Dict[str, str]]):
        """
        è¿½åŠ  QA å¯¹åˆ° JSONL æ–‡ä»¶

        Args:
            qa_pairs: QA å¯¹åˆ—è¡¨
        """
        with open(self.output_file, 'a', encoding='utf-8') as f:
            for pair in qa_pairs:
                json_line = json.dumps(pair, ensure_ascii=False)
                f.write(json_line + '\n')

    def _save_checkpoint(self, checkpoint_file: Path, data: dict):
        """ä¿å­˜æ–­ç‚¹ä¿¡æ¯"""
        with open(checkpoint_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        self.logger.debug(f"ğŸ’¾ å·²ä¿å­˜æ–­ç‚¹: {checkpoint_file}")

    def _load_checkpoint(self, checkpoint_file: Path) -> dict:
        """åŠ è½½æ–­ç‚¹ä¿¡æ¯"""
        with open(checkpoint_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        self.logger.debug(f"ğŸ“‚ å·²åŠ è½½æ–­ç‚¹: {checkpoint_file}")
        return data


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    import asyncio

    async def test_distiller():
        """æµ‹è¯•æ•°æ®è’¸é¦åŠŸèƒ½"""
        # åˆ›å»ºè’¸é¦å™¨ï¼ˆä½¿ç”¨ Geminiï¼‰
        distiller = DataDistillerSkill(
            api_provider='gemini',
            output_file='data/output/dataset.jsonl',
            chunk_size=2000,
            qa_per_chunk=5
        )

        # æµ‹è¯•æ–‡æœ¬
        test_content = """
# è´¢åŠ¡æŠ¥é”€åˆ¶åº¦

## å·®æ—…è´¹æŠ¥é”€

1. å‡ºå·®ç”³è¯·ï¼šå‘˜å·¥å‡ºå·®å‰éœ€å¡«å†™ã€Šå‡ºå·®ç”³è¯·å•ã€‹ï¼Œç»éƒ¨é—¨ç»ç†å®¡æ‰¹åæ–¹å¯å‡ºå·®ã€‚
2. æŠ¥é”€æ ‡å‡†ï¼š
   - äº¤é€šè´¹ï¼šå®æŠ¥å®é”€ï¼Œéœ€æä¾›å‘ç¥¨
   - ä½å®¿è´¹ï¼šä¸€çº¿åŸå¸‚ä¸è¶…è¿‡500å…ƒ/å¤©ï¼ŒäºŒçº¿åŸå¸‚ä¸è¶…è¿‡300å…ƒ/å¤©
   - é¤è´¹ï¼š100å…ƒ/å¤©
3. æŠ¥é”€æ—¶é™ï¼šå‡ºå·®ç»“æŸå15ä¸ªå·¥ä½œæ—¥å†…å®ŒæˆæŠ¥é”€
4. æ‰€éœ€ææ–™ï¼šå‡ºå·®ç”³è¯·å•ã€å‘ç¥¨åŸä»¶ã€è¡Œç¨‹å•

## åŠå…¬ç”¨å“æŠ¥é”€

1. é‡‡è´­æµç¨‹ï¼šç”±è¡Œæ”¿éƒ¨ç»Ÿä¸€é‡‡è´­
2. æŠ¥é”€æ ‡å‡†ï¼šæ¯äººæ¯æœˆä¸è¶…è¿‡200å…ƒ
3. å®¡æ‰¹æµç¨‹ï¼šéƒ¨é—¨ç»ç†å®¡æ‰¹ â†’ è´¢åŠ¡å®¡æ ¸ â†’ æ€»ç»ç†æ‰¹å‡†
        """

        print(f"\n{'='*60}")
        print("æµ‹è¯•æ•°æ®è’¸é¦")
        print('='*60)

        result = await distiller.run(test_content, source_file='test_policy.md')

        if result['success']:
            data = result['data']
            print(f"âœ… è’¸é¦æˆåŠŸ:")
            print(f"   ç”Ÿæˆ QA å¯¹: {data['total_qa_pairs']} ä¸ª")
            print(f"   è¾“å‡ºæ–‡ä»¶: {data['output_file']}")
            print(f"   å¤„ç†å—æ•°: {data['chunks_processed']}")
            print(f"   API è°ƒç”¨: {data['api_calls']} æ¬¡")
        else:
            print(f"âŒ è’¸é¦å¤±è´¥: {result['error']}")

    # è¿è¡Œæµ‹è¯•
    asyncio.run(test_distiller())
