"""
SmartChunkerSkill - æ™ºèƒ½æ–‡æœ¬åˆ‡åˆ†å™¨

è´Ÿè´£å°†é•¿æ–‡æœ¬è¿›è¡Œé€»è¾‘åˆ‡åˆ†ï¼š
1. æ”¯æŒè‡ªå®šä¹‰ chunk_size å’Œ overlap
2. æ™ºèƒ½è¯†åˆ«æ®µè½ã€å¥å­è¾¹ç•Œï¼Œé¿å…è¯­ä¹‰æˆªæ–­
3. ä¿ç•™æ–‡æ¡£ç»“æ„ä¿¡æ¯ï¼ˆå¦‚æ ‡é¢˜å±‚çº§ï¼‰
4. æ”¯æŒå¤šç§åˆ‡åˆ†ç­–ç•¥ï¼ˆæŒ‰å­—ç¬¦ã€æŒ‰å¥å­ã€æŒ‰æ®µè½ï¼‰
"""

import asyncio
import re
from typing import Dict, Any, List, Optional
from .base_skill import BaseSkill


class SmartChunkerSkill(BaseSkill):
    """
    æ™ºèƒ½æ–‡æœ¬åˆ‡åˆ† Skill

    å°†é•¿æ–‡æœ¬åˆ‡åˆ†ä¸ºåˆé€‚å¤§å°çš„å—ï¼ŒåŒæ—¶ä¿æŒè¯­ä¹‰å®Œæ•´æ€§
    """

    def __init__(self,
                 chunk_size: int = 1000,
                 overlap: int = 200,
                 strategy: str = 'smart',
                 respect_structure: bool = True):
        """
        åˆå§‹åŒ– SmartChunkerSkill

        Args:
            chunk_size: æ¯ä¸ªå—çš„ç›®æ ‡å­—ç¬¦æ•°ï¼ˆé»˜è®¤ 1000ï¼‰
            overlap: å—ä¹‹é—´çš„é‡å å­—ç¬¦æ•°ï¼ˆé»˜è®¤ 200ï¼‰
            strategy: åˆ‡åˆ†ç­–ç•¥
                - 'smart': æ™ºèƒ½åˆ‡åˆ†ï¼ˆä¼˜å…ˆåœ¨æ®µè½/å¥å­è¾¹ç•Œåˆ‡åˆ†ï¼‰
                - 'sentence': æŒ‰å¥å­åˆ‡åˆ†
                - 'paragraph': æŒ‰æ®µè½åˆ‡åˆ†
                - 'fixed': å›ºå®šé•¿åº¦åˆ‡åˆ†
            respect_structure: æ˜¯å¦å°Šé‡æ–‡æ¡£ç»“æ„ï¼ˆå¦‚æ ‡é¢˜å±‚çº§ï¼‰
        """
        super().__init__(name="SmartChunker")
        self.chunk_size = chunk_size
        self.overlap = overlap
        self.strategy = strategy
        self.respect_structure = respect_structure

        # éªŒè¯ç­–ç•¥
        valid_strategies = ['smart', 'sentence', 'paragraph', 'fixed']
        if self.strategy not in valid_strategies:
            raise ValueError(
                f"ä¸æ”¯æŒçš„åˆ‡åˆ†ç­–ç•¥: {strategy}\n"
                f"æ”¯æŒçš„ç­–ç•¥: {', '.join(valid_strategies)}"
            )

    async def execute(self, input_data: Any, **kwargs) -> Dict[str, Any]:
        """
        æ‰§è¡Œæ–‡æœ¬åˆ‡åˆ†

        Args:
            input_data: è§£æç»“æœå­—å…¸ï¼ˆåŒ…å« content å’Œ structureï¼‰
            **kwargs: é¢å¤–å‚æ•°
                - chunk_size: è¦†ç›–é»˜è®¤çš„å—å¤§å°
                - overlap: è¦†ç›–é»˜è®¤çš„é‡å å¤§å°

        Returns:
            {
                'file_path': str,
                'chunks': List[Dict],     # åˆ‡åˆ†åçš„å—åˆ—è¡¨
                'chunk_count': int,       # å—çš„æ•°é‡
                'metadata': dict          # åˆ‡åˆ†å…ƒæ•°æ®
            }

        Raises:
            ValueError: è¾“å…¥æ•°æ®æ ¼å¼é”™è¯¯
        """
        # éªŒè¯è¾“å…¥
        if not isinstance(input_data, dict):
            raise ValueError("è¾“å…¥å¿…é¡»æ˜¯è§£æç»“æœå­—å…¸")

        if 'content' not in input_data:
            raise ValueError("è¾“å…¥å­—å…¸å¿…é¡»åŒ…å« 'content' å­—æ®µ")

        # è·å–å‚æ•°
        chunk_size = kwargs.get('chunk_size', self.chunk_size)
        overlap = kwargs.get('overlap', self.overlap)

        content = input_data['content']
        structure = input_data.get('structure', [])
        file_path = input_data.get('file_path', 'unknown')

        self.logger.info(
            f"ğŸ“ å¼€å§‹åˆ‡åˆ†æ–‡æœ¬: é•¿åº¦={len(content)}, "
            f"ç­–ç•¥={self.strategy}, chunk_size={chunk_size}"
        )

        # æ ¹æ®ç­–ç•¥é€‰æ‹©åˆ‡åˆ†æ–¹æ³•
        if self.strategy == 'smart':
            chunks = await self._smart_chunk(content, structure, chunk_size, overlap)
        elif self.strategy == 'sentence':
            chunks = await self._sentence_chunk(content, chunk_size, overlap)
        elif self.strategy == 'paragraph':
            chunks = await self._paragraph_chunk(content, chunk_size, overlap)
        elif self.strategy == 'fixed':
            chunks = await self._fixed_chunk(content, chunk_size, overlap)

        self.logger.info(f"âœ… åˆ‡åˆ†å®Œæˆ: å…± {len(chunks)} ä¸ªå—")

        return {
            'file_path': file_path,
            'chunks': chunks,
            'chunk_count': len(chunks),
            'metadata': {
                'original_length': len(content),
                'chunk_size': chunk_size,
                'overlap': overlap,
                'strategy': self.strategy,
                'avg_chunk_size': sum(len(c['text']) for c in chunks) / len(chunks) if chunks else 0
            }
        }

    async def _smart_chunk(self,
                          content: str,
                          structure: List[Dict],
                          chunk_size: int,
                          overlap: int) -> List[Dict]:
        """
        æ™ºèƒ½åˆ‡åˆ†ï¼šä¼˜å…ˆåœ¨æ®µè½/å¥å­è¾¹ç•Œåˆ‡åˆ†

        Args:
            content: æ–‡æœ¬å†…å®¹
            structure: æ–‡æ¡£ç»“æ„ä¿¡æ¯
            chunk_size: å—å¤§å°
            overlap: é‡å å¤§å°

        Returns:
            åˆ‡åˆ†åçš„å—åˆ—è¡¨
        """
        chunks = []

        # å¦‚æœæ–‡æœ¬å¾ˆçŸ­ï¼Œç›´æ¥è¿”å›
        if len(content) <= chunk_size:
            return [{
                'chunk_id': 0,
                'text': content,
                'start_pos': 0,
                'end_pos': len(content),
                'metadata': {}
            }]

        # å…ˆæŒ‰æ®µè½åˆ†å‰²
        paragraphs = self._split_paragraphs(content)

        current_chunk = []
        current_size = 0
        chunk_id = 0
        start_pos = 0

        for para in paragraphs:
            para_len = len(para)

            # å¦‚æœå½“å‰æ®µè½åŠ å…¥åè¶…è¿‡ chunk_size
            if current_size + para_len > chunk_size and current_chunk:
                # ä¿å­˜å½“å‰å—
                chunk_text = '\n\n'.join(current_chunk)
                chunks.append({
                    'chunk_id': chunk_id,
                    'text': chunk_text,
                    'start_pos': start_pos,
                    'end_pos': start_pos + len(chunk_text),
                    'metadata': self._extract_chunk_metadata(chunk_text, structure)
                })

                # è®¡ç®—é‡å éƒ¨åˆ†
                overlap_text = self._get_overlap_text(current_chunk, overlap)
                current_chunk = [overlap_text] if overlap_text else []
                current_size = len(overlap_text) if overlap_text else 0
                start_pos = start_pos + len(chunk_text) - current_size
                chunk_id += 1

            # å¦‚æœå•ä¸ªæ®µè½å°±è¶…è¿‡ chunk_sizeï¼Œéœ€è¦æŒ‰å¥å­åˆ‡åˆ†
            if para_len > chunk_size:
                sentences = self._split_sentences(para)
                for sentence in sentences:
                    if current_size + len(sentence) > chunk_size and current_chunk:
                        # ä¿å­˜å½“å‰å—
                        chunk_text = '\n\n'.join(current_chunk)
                        chunks.append({
                            'chunk_id': chunk_id,
                            'text': chunk_text,
                            'start_pos': start_pos,
                            'end_pos': start_pos + len(chunk_text),
                            'metadata': self._extract_chunk_metadata(chunk_text, structure)
                        })

                        overlap_text = self._get_overlap_text(current_chunk, overlap)
                        current_chunk = [overlap_text] if overlap_text else []
                        current_size = len(overlap_text) if overlap_text else 0
                        start_pos = start_pos + len(chunk_text) - current_size
                        chunk_id += 1

                    current_chunk.append(sentence)
                    current_size += len(sentence)
            else:
                current_chunk.append(para)
                current_size += para_len

        # ä¿å­˜æœ€åä¸€ä¸ªå—
        if current_chunk:
            chunk_text = '\n\n'.join(current_chunk)
            chunks.append({
                'chunk_id': chunk_id,
                'text': chunk_text,
                'start_pos': start_pos,
                'end_pos': start_pos + len(chunk_text),
                'metadata': self._extract_chunk_metadata(chunk_text, structure)
            })

        return chunks

    async def _sentence_chunk(self,
                             content: str,
                             chunk_size: int,
                             overlap: int) -> List[Dict]:
        """
        æŒ‰å¥å­åˆ‡åˆ†

        Args:
            content: æ–‡æœ¬å†…å®¹
            chunk_size: å—å¤§å°
            overlap: é‡å å¤§å°

        Returns:
            åˆ‡åˆ†åçš„å—åˆ—è¡¨
        """
        sentences = self._split_sentences(content)
        chunks = []

        current_chunk = []
        current_size = 0
        chunk_id = 0
        start_pos = 0

        for sentence in sentences:
            sentence_len = len(sentence)

            if current_size + sentence_len > chunk_size and current_chunk:
                # ä¿å­˜å½“å‰å—
                chunk_text = ' '.join(current_chunk)
                chunks.append({
                    'chunk_id': chunk_id,
                    'text': chunk_text,
                    'start_pos': start_pos,
                    'end_pos': start_pos + len(chunk_text),
                    'metadata': {}
                })

                # è®¡ç®—é‡å 
                overlap_sentences = self._get_overlap_sentences(current_chunk, overlap)
                current_chunk = overlap_sentences
                current_size = sum(len(s) for s in overlap_sentences)
                start_pos = start_pos + len(chunk_text) - current_size
                chunk_id += 1

            current_chunk.append(sentence)
            current_size += sentence_len

        # ä¿å­˜æœ€åä¸€ä¸ªå—
        if current_chunk:
            chunk_text = ' '.join(current_chunk)
            chunks.append({
                'chunk_id': chunk_id,
                'text': chunk_text,
                'start_pos': start_pos,
                'end_pos': start_pos + len(chunk_text),
                'metadata': {}
            })

        return chunks

    async def _paragraph_chunk(self,
                              content: str,
                              chunk_size: int,
                              overlap: int) -> List[Dict]:
        """
        æŒ‰æ®µè½åˆ‡åˆ†

        Args:
            content: æ–‡æœ¬å†…å®¹
            chunk_size: å—å¤§å°
            overlap: é‡å å¤§å°

        Returns:
            åˆ‡åˆ†åçš„å—åˆ—è¡¨
        """
        paragraphs = self._split_paragraphs(content)
        chunks = []

        current_chunk = []
        current_size = 0
        chunk_id = 0
        start_pos = 0

        for para in paragraphs:
            para_len = len(para)

            if current_size + para_len > chunk_size and current_chunk:
                # ä¿å­˜å½“å‰å—
                chunk_text = '\n\n'.join(current_chunk)
                chunks.append({
                    'chunk_id': chunk_id,
                    'text': chunk_text,
                    'start_pos': start_pos,
                    'end_pos': start_pos + len(chunk_text),
                    'metadata': {}
                })

                # é‡å å¤„ç†
                overlap_text = self._get_overlap_text(current_chunk, overlap)
                current_chunk = [overlap_text] if overlap_text else []
                current_size = len(overlap_text) if overlap_text else 0
                start_pos = start_pos + len(chunk_text) - current_size
                chunk_id += 1

            current_chunk.append(para)
            current_size += para_len

        # ä¿å­˜æœ€åä¸€ä¸ªå—
        if current_chunk:
            chunk_text = '\n\n'.join(current_chunk)
            chunks.append({
                'chunk_id': chunk_id,
                'text': chunk_text,
                'start_pos': start_pos,
                'end_pos': start_pos + len(chunk_text),
                'metadata': {}
            })

        return chunks

    async def _fixed_chunk(self,
                          content: str,
                          chunk_size: int,
                          overlap: int) -> List[Dict]:
        """
        å›ºå®šé•¿åº¦åˆ‡åˆ†ï¼ˆä¸è€ƒè™‘è¯­ä¹‰è¾¹ç•Œï¼‰

        Args:
            content: æ–‡æœ¬å†…å®¹
            chunk_size: å—å¤§å°
            overlap: é‡å å¤§å°

        Returns:
            åˆ‡åˆ†åçš„å—åˆ—è¡¨
        """
        chunks = []
        chunk_id = 0
        start = 0

        while start < len(content):
            end = start + chunk_size
            chunk_text = content[start:end]

            chunks.append({
                'chunk_id': chunk_id,
                'text': chunk_text,
                'start_pos': start,
                'end_pos': end,
                'metadata': {}
            })

            start = end - overlap
            chunk_id += 1

        return chunks

    def _split_paragraphs(self, text: str) -> List[str]:
        """
        æŒ‰æ®µè½åˆ†å‰²æ–‡æœ¬

        Args:
            text: æ–‡æœ¬å†…å®¹

        Returns:
            æ®µè½åˆ—è¡¨
        """
        # æŒ‰åŒæ¢è¡Œç¬¦åˆ†å‰²
        paragraphs = re.split(r'\n\s*\n', text)
        return [p.strip() for p in paragraphs if p.strip()]

    def _split_sentences(self, text: str) -> List[str]:
        """
        æŒ‰å¥å­åˆ†å‰²æ–‡æœ¬

        Args:
            text: æ–‡æœ¬å†…å®¹

        Returns:
            å¥å­åˆ—è¡¨
        """
        # ä¸­è‹±æ–‡å¥å­åˆ†å‰²
        sentences = re.split(r'([ã€‚ï¼ï¼Ÿ\.!?]+)', text)

        # åˆå¹¶æ ‡ç‚¹ç¬¦å·
        result = []
        for i in range(0, len(sentences) - 1, 2):
            sentence = sentences[i] + (sentences[i + 1] if i + 1 < len(sentences) else '')
            sentence = sentence.strip()
            if sentence:
                result.append(sentence)

        # å¤„ç†æœ€åä¸€ä¸ªå¥å­ï¼ˆå¦‚æœæ²¡æœ‰æ ‡ç‚¹ï¼‰
        if len(sentences) % 2 == 1 and sentences[-1].strip():
            result.append(sentences[-1].strip())

        return result

    def _get_overlap_text(self, chunks: List[str], overlap: int) -> str:
        """
        è·å–é‡å æ–‡æœ¬

        Args:
            chunks: å½“å‰å—åˆ—è¡¨
            overlap: é‡å å­—ç¬¦æ•°

        Returns:
            é‡å æ–‡æœ¬
        """
        if not chunks:
            return ''

        # ä»æœ€åçš„å—ä¸­æå– overlap é•¿åº¦çš„æ–‡æœ¬
        combined = '\n\n'.join(chunks)
        if len(combined) <= overlap:
            return combined

        return combined[-overlap:]

    def _get_overlap_sentences(self, sentences: List[str], overlap: int) -> List[str]:
        """
        è·å–é‡å çš„å¥å­

        Args:
            sentences: å¥å­åˆ—è¡¨
            overlap: é‡å å­—ç¬¦æ•°

        Returns:
            é‡å çš„å¥å­åˆ—è¡¨
        """
        if not sentences:
            return []

        overlap_sentences = []
        current_size = 0

        # ä»åå¾€å‰ç´¯åŠ å¥å­ï¼Œç›´åˆ°è¾¾åˆ° overlap å¤§å°
        for sentence in reversed(sentences):
            if current_size >= overlap:
                break
            overlap_sentences.insert(0, sentence)
            current_size += len(sentence)

        return overlap_sentences

    def _extract_chunk_metadata(self,
                                chunk_text: str,
                                structure: List[Dict]) -> Dict[str, Any]:
        """
        æå–å—çš„å…ƒæ•°æ®ï¼ˆå¦‚æ‰€å±ç« èŠ‚ï¼‰

        Args:
            chunk_text: å—æ–‡æœ¬
            structure: æ–‡æ¡£ç»“æ„ä¿¡æ¯

        Returns:
            å…ƒæ•°æ®å­—å…¸
        """
        if not self.respect_structure or not structure:
            return {}

        metadata = {}

        # æŸ¥æ‰¾å—ä¸­çš„æ ‡é¢˜
        for item in structure:
            if 'title' in item and item['title'] in chunk_text:
                metadata['section'] = item['title']
                metadata['level'] = item.get('level', 0)
                break

        return metadata


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    import asyncio

    async def test_chunker():
        """æµ‹è¯•æ–‡æœ¬åˆ‡åˆ†åŠŸèƒ½"""
        chunker = SmartChunkerSkill(
            chunk_size=500,
            overlap=100,
            strategy='smart'
        )

        # æµ‹è¯•æ–‡æœ¬
        test_content = """
        # ç¬¬ä¸€ç«  å¼•è¨€

        è¿™æ˜¯ç¬¬ä¸€ç« çš„å†…å®¹ã€‚äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ã€‚å®ƒä¼å›¾äº†è§£æ™ºèƒ½çš„å®è´¨ã€‚

        ## 1.1 èƒŒæ™¯

        äººå·¥æ™ºèƒ½çš„ç ”ç©¶å§‹äº20ä¸–çºª50å¹´ä»£ã€‚æ—©æœŸçš„ç ”ç©¶è€…ä»¬å¯¹äººå·¥æ™ºèƒ½å……æ»¡äº†ä¹è§‚ã€‚

        # ç¬¬äºŒç«  æœºå™¨å­¦ä¹ 

        æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ã€‚å®ƒä½¿è®¡ç®—æœºèƒ½å¤Ÿä»æ•°æ®ä¸­å­¦ä¹ ã€‚
        """ * 5  # é‡å¤ä»¥äº§ç”Ÿæ›´é•¿çš„æ–‡æœ¬

        input_data = {
            'file_path': 'test.md',
            'content': test_content,
            'structure': [
                {'level': 1, 'title': 'ç¬¬ä¸€ç«  å¼•è¨€'},
                {'level': 2, 'title': '1.1 èƒŒæ™¯'},
                {'level': 1, 'title': 'ç¬¬äºŒç«  æœºå™¨å­¦ä¹ '}
            ]
        }

        print(f"\n{'='*60}")
        print(f"æµ‹è¯•æ™ºèƒ½åˆ‡åˆ†")
        print('='*60)

        result = await chunker.run(input_data)

        if result['success']:
            data = result['data']
            print(f"âœ… åˆ‡åˆ†æˆåŠŸ:")
            print(f"   åŸå§‹é•¿åº¦: {data['metadata']['original_length']}")
            print(f"   å—æ•°é‡: {data['chunk_count']}")
            print(f"   å¹³å‡å—å¤§å°: {data['metadata']['avg_chunk_size']:.0f}")

            print(f"\nå‰ 3 ä¸ªå—:")
            for chunk in data['chunks'][:3]:
                print(f"\n   --- Chunk {chunk['chunk_id']} ---")
                print(f"   é•¿åº¦: {len(chunk['text'])}")
                print(f"   é¢„è§ˆ: {chunk['text'][:100]}...")
                if chunk['metadata']:
                    print(f"   å…ƒæ•°æ®: {chunk['metadata']}")
        else:
            print(f"âŒ åˆ‡åˆ†å¤±è´¥: {result['error']}")

        # æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯
        print(f"\n{'='*60}")
        print("ç»Ÿè®¡ä¿¡æ¯:")
        print('='*60)
        stats = chunker.get_stats()
        for key, value in stats.items():
            print(f"   {key}: {value}")

    # è¿è¡Œæµ‹è¯•
    asyncio.run(test_chunker())
