# 准确率低的原因分析

**分析日期**: 2026-02-28
**模型**: Qwen2.5-3B
**当前准确率**: 40% (严格模式) / 80% (宽松模式)

---

## 📊 准确率现状

### 评估结果对比

| 评估模式 | 测试用例数 | 正确数 | 准确率 | 说明 |
|---------|-----------|--------|--------|------|
| **严格模式** | 12 | 5 | 40% | 需要包含所有预期关键词 |
| **宽松模式** | 5 | 4 | 80% | 只需要部分关键词匹配 |
| **test_set模式** | 20 | 0 | 0% | 最严格的评估 |

### 数字类问题表现

| 问题类型 | 测试数 | 正确数 | 准确率 | 状态 |
|---------|--------|--------|--------|------|
| **金额阈值类** | 5 | 0 | 0% | 🔴 严重问题 |
| **流程材料类** | 4 | 3 | 75% | 🟡 中等 |
| **一般问答类** | 3 | 2 | 67% | 🟡 中等 |

---

## 🔍 根本原因分析

### 原因1: 训练数据质量问题 🔴

#### 1.1 数字类问题占比过低

**统计数据**:
```
总训练数据: 863条
数字类问题: ~43条 (5%)
非数字问题: ~820条 (95%)
```

**问题影响**:
- 模型在训练时接触到数字类问题的机会太少
- 模型没有学会如何准确记忆和输出数字
- 导致在测试时无法正确回答数字相关问题

**证据**:
```json
// 训练数据示例（非数字问题）
{
  "instruction": "根据文本，华东师范大学财务报销细则的制定目的是什么？",
  "output": "华东师范大学财务报销细则的制定目的是为了规范学校经费支出管理，提高资金使用效益。"
}

// 缺少类似这样的数字问题：
{
  "instruction": "图书资料报销在什么金额以上需要附合同？",
  "output": "图书资料单价在30000元以上的，需要附合同。"
}
```

#### 1.2 训练数据本身存在错误

**错误案例1**: 图书合同金额
```
训练数据中的错误答案:
"图书、资料、软件等单价在500元以上的，需附合同。"

正确答案（来自文档）:
"图书、资料、软件等单价在30000元以上的，需附合同。"
```

**错误案例2**: 课题协作费
```
训练数据可能包含不一致的金额阈值
- 有的说3000元
- 有的说5000元
- 模型学习了错误的信息
```

#### 1.3 数据蒸馏质量不稳定

**LLM生成的问题**:
- 智谱AI/Gemini API生成的问答对质量参差不齐
- 没有进行人工验证
- 错误数据直接进入训练集

**问题表现**:
```
模型回答示例:
"华东师大对办公用纸、办公用品、办公耗材、办公设备、办公家具、
办公软件、办公服务等的报销有特殊规定，如办公用具、办公用书、
办公文具、复印纸、打印纸、传真纸、信封、信纸、订书机、回形针、
胶水、胶带、胶棒、胶条、胶圈、胶钉、胶布、胶纸、胶贴、胶枪、
胶管、胶桶、胶盒、胶箱、胶袋、胶杯、胶碗、胶盆、胶盘、胶碟、
胶勺、胶叉、胶铲、胶刷、胶笔、胶尺、胶刀、胶剪、胶钳、胶锤、
胶榔头、胶扳手、胶螺丝刀、"
```

**问题分析**:
- 模型只是在列举物品，没有回答具体规定
- 没有提到"500元以上需要明细清单"这个关键信息
- 说明训练数据中这类问题的质量很差

---

### 原因2: 模型容量限制 🟡

#### 2.1 3B模型参数量相对较小

**模型对比**:
| 模型 | 参数量 | 推荐训练数据量 | 当前数据量 | 是否足够 |
|------|--------|--------------|-----------|---------|
| Qwen2.5-0.5B | 462M | 100-500条 | 863条 | ✅ 足够 |
| Qwen2.5-1.5B | 1.5B | 500-1000条 | 863条 | 🟡 临界 |
| Qwen2.5-3B | 3B | 1000-3000条 | 863条 | ❌ 不足 |
| Qwen2.5-7B | 7B | 3000-10000条 | 863条 | ❌ 严重不足 |

**问题分析**:
- 3B模型需要1000-3000条高质量训练数据
- 当前只有863条，且质量不高
- 模型容量不足以记忆所有专业知识

#### 2.2 LoRA适配能力有限

**当前配置**:
```yaml
lora:
  rank: 16              # LoRA秩
  alpha: 32             # 缩放因子
  trainable_params: ~0.5%  # 只训练0.5%的参数
```

**问题**:
- LoRA只训练0.5%的参数，适配能力有限
- 对于复杂的领域知识，可能需要更大的rank
- 当前rank=16可能不足以捕获所有领域知识

---

### 原因3: 训练策略问题 🟡

#### 3.1 训练轮数可能不足

**当前配置**:
```yaml
training:
  num_epochs: 3
```

**问题**:
- 3个epoch可能不足以让模型充分学习
- 特别是对于数字类问题，需要更多重复
- 建议增加到5-10个epoch

#### 3.2 学习率可能需要调整

**当前配置**:
```yaml
training:
  learning_rate: 0.00005  # 5e-5
```

**问题**:
- 学习率可能太小，导致学习速度慢
- 或者太大，导致不稳定
- 需要根据训练曲线动态调整

#### 3.3 缺少数据增强

**当前情况**:
- 没有使用数据增强技术
- 每个知识点只有1-2个问答对
- 模型没有足够的变体学习

**建议的数据增强方法**:
```python
1. 同义词替换
   "图书资料" → "书籍资料" / "图书和资料"

2. 问题改写
   "图书资料报销在什么金额以上需要附合同？"
   → "什么金额的图书资料需要附合同？"
   → "图书资料超过多少金额要附合同？"

3. 答案变体
   "30000元以上" → "超过30000元" / "大于30000元"
```

---

### 原因4: 评估标准严格 🔴

#### 4.1 严格模式要求过高

**评估标准**:
```python
# 严格模式：必须包含所有预期关键词
expected_keywords = ["30000", "合同", "图书"]
found_keywords = ["合同", "图书"]
missing_keywords = ["30000"]
is_correct = False  # 因为缺少"30000"
```

**问题**:
- 即使回答了大部分信息，只要缺少一个关键词就算错误
- 对于数字类问题特别严格
- 导致准确率偏低

#### 4.2 测试用例可能不均衡

**测试用例分布**:
```
数字类问题: 5个 (42%)
流程类问题: 4个 (33%)
一般问答: 3个 (25%)
```

**问题**:
- 数字类问题占比过高
- 而这正是模型的弱项
- 导致整体准确率偏低

---

### 原因5: 领域知识复杂性 🟡

#### 5.1 财务报销规则复杂

**文档特点**:
- 50页PDF文档
- 包含大量具体的金额阈值
- 不同类型的费用有不同的规定
- 规则之间存在交叉和例外

**示例**:
```
课题协作费: 3000元协议，10000元合同
制作费: 3000元协议，10000元合同
材料费: 3000元协议，10000元合同
图书资料: 500元明细清单，30000元合同
办公用品: 500元明细清单
```

**问题**:
- 大量相似的规则容易混淆
- 模型难以精确记忆每个阈值
- 容易产生幻觉

#### 5.2 专业术语多

**专业术语**:
- 协议、合同、审批单、明细清单
- 课题协作费、制作费、材料费
- 差旅费、会议费、市内交通补助
- ...

**问题**:
- 模型需要学习大量专业术语
- 术语之间的关系复杂
- 需要大量训练数据才能掌握

---

## 💡 解决方案

### 短期方案（1-2周）

#### 方案1: 人工编写高质量数字问题 👨‍💻

**目标**: 编写50-100个高质量数字类问题

**方法**:
```python
# 步骤1: 提取所有数字阈值
从文档中提取:
- 课题协作费: 3000元协议，10000元合同
- 制作费: 3000元协议，10000元合同
- 材料费: 3000元协议，10000元合同
- 图书资料: 500元明细清单，30000元合同
- 办公用品: 500元明细清单
- ...

# 步骤2: 为每个阈值编写多个问题
示例:
1. "课题协作费在什么金额以上需要签订协议？"
   答案: "课题协作费单张或累计金额3000元以上需要签订协议。"

2. "课题协作费达到多少金额需要签订合同？"
   答案: "课题协作费单张或累计金额10000元以上需要签订合同。"

3. "3000元的课题协作费需要提供什么材料？"
   答案: "需要提供协议。"

4. "10000元的课题协作费需要提供什么材料？"
   答案: "需要提供合同。"

# 步骤3: 人工验证每个答案的准确性
# 步骤4: 保存为JSONL格式
```

**预期效果**:
- 数字类问题占比从5%提升到20-30%
- 数字准确率从0%提升到70%+
- 整体准确率从40%提升到60%+

#### 方案2: 清洗和修正训练数据 🧹

**目标**: 修正训练数据中的错误

**方法**:
```python
# 步骤1: 识别错误数据
使用规则和人工审核识别:
- 数字不匹配的问题
- 答案与文档不符的问题
- 包含幻觉信息的问题

# 步骤2: 修正错误
- 删除无法修正的错误数据
- 修正可以修正的数据
- 标记需要人工审核的数据

# 步骤3: 验证修正后的数据
- 随机抽样检查
- 确保所有数字准确
- 确保所有答案与文档一致
```

**预期效果**:
- 训练数据质量显著提升
- 减少模型幻觉
- 提高整体准确率

#### 方案3: 增加训练轮数 🔄

**目标**: 让模型充分学习

**配置调整**:
```yaml
training:
  num_epochs: 5-10  # 从3增加到5-10
  learning_rate: 0.00003  # 相应降低学习率
```

**预期效果**:
- 模型有更多机会学习数字信息
- 数字准确率可能提升
- 需要监控过拟合

---

### 中期方案（1个月）

#### 方案4: 使用更强的LLM进行数据蒸馏 🔋

**目标**: 生成更高质量的训练数据

**方法**:
```python
# 使用GPT-4或其他更强的LLM
from openai import OpenAI

client = OpenAI(api_key="your_key")

# 更强的提示词
prompt = """
你是一个财务专家。请根据以下文档生成问答对。

要求：
1. 必须包含准确的数字信息
2. 答案必须与文档完全一致
3. 优先生成数字类问题（占比30%以上）
4. 每个数字阈值生成至少3个不同的问题

文档内容：{document}
"""

# 生成数据
response = client.chat.completions.create(
    model="gpt-4",
    messages=[{"role": "user", "content": prompt}]
)
```

**预期效果**:
- 数据质量显著提升
- 数字准确率提高
- 减少幻觉

#### 方案5: 增加LoRA rank 📈

**目标**: 提高模型适配能力

**配置调整**:
```yaml
lora:
  rank: 32  # 从16增加到32
  alpha: 64  # rank × 2
```

**预期效果**:
- 模型适配能力提升
- 可以学习更多领域知识
- 需要更多显存

#### 方案6: 实施两阶段训练 🎯

**目标**: 先学习领域知识，再学习问答

**阶段1: 领域预训练**
```python
# 在原始领域文本上预训练
domain_texts = load_all_pdf_texts(["财务细则.pdf"])

trainer.pretrain(
    texts=domain_texts,
    epochs=2,
    learning_rate=0.0001
)
```

**阶段2: 指令微调**
```python
# 在问答对上微调
trainer.finetune(
    qa_pairs=distilled_data,
    epochs=3,
    learning_rate=0.0002
)
```

**预期效果**:
- 模型先学习领域知识结构
- 再学习如何回答问题
- 提升事实准确性

---

### 长期方案（3个月）

#### 方案7: 升级到更大的模型 🚀

**目标**: 使用7B模型

**配置**:
```yaml
model:
  base_model: "models/Qwen/Qwen2.5-7B"

training:
  num_epochs: 3-5
  learning_rate: 0.00003
```

**预期效果**:
- 模型容量大幅提升
- 可以处理更复杂的知识
- 准确率预期提升到70%+

**代价**:
- 训练时间增加2-3倍
- 推理速度降低40-60%
- 需要更多显存（8GB+）

#### 方案8: 引入RAG验证 🔍

**目标**: 使用检索增强生成

**方法**:
```python
class RAGEnhancedInferencer:
    def generate_with_verification(self, question):
        # 1. 生成答案
        answer = self.model.generate(question)

        # 2. 检索相关段落
        relevant_docs = self.retrieve(question, top_k=3)

        # 3. 事实一致性检查
        consistency = self.verify_consistency(answer, relevant_docs)

        if consistency < 0.8:
            # 重新生成或标记不确定
            return self.generate_with_context(question, relevant_docs)

        return answer
```

**预期效果**:
- 减少幻觉
- 提高数字准确性
- 提供可追溯的答案来源

---

## 📈 预期改进效果

### 短期改进（1-2周）

| 指标 | 当前 | 目标 | 提升 |
|------|------|------|------|
| 整体准确率 | 40% | 60% | +20% |
| 数字准确率 | 0% | 70% | +70% |
| 关键词覆盖率 | 63% | 80% | +17% |

### 中期改进（1个月）

| 指标 | 当前 | 目标 | 提升 |
|------|------|------|------|
| 整体准确率 | 40% | 70% | +30% |
| 数字准确率 | 0% | 80% | +80% |
| 关键词覆盖率 | 63% | 85% | +22% |

### 长期改进（3个月）

| 指标 | 当前 | 目标 | 提升 |
|------|------|------|------|
| 整体准确率 | 40% | 85%+ | +45% |
| 数字准确率 | 0% | 90%+ | +90% |
| 关键词覆盖率 | 63% | 90%+ | +27% |

---

## 🎯 总结

### 准确率低的主要原因

1. **训练数据质量问题** (最关键)
   - 数字类问题占比过低（5% vs 目标30%）
   - 训练数据本身存在错误
   - 数据蒸馏质量不稳定

2. **模型容量限制**
   - 3B模型需要1000-3000条数据，当前只有863条
   - LoRA适配能力有限

3. **训练策略问题**
   - 训练轮数可能不足
   - 缺少数据增强

4. **评估标准严格**
   - 严格模式要求包含所有关键词
   - 数字类问题测试占比过高

5. **领域知识复杂性**
   - 财务报销规则复杂
   - 大量相似规则容易混淆

### 优先级建议

**立即行动**:
1. 人工编写50个高质量数字类问题
2. 清洗和修正训练数据中的错误
3. 增加训练轮数到5-10

**短期计划**:
4. 使用更强的LLM（GPT-4）进行数据蒸馏
5. 增加LoRA rank到32
6. 实施两阶段训练

**长期规划**:
7. 升级到7B模型
8. 引入RAG验证

### 关键要点

- **数据质量 > 数据数量**: 宁可要100条高质量数据，也不要1000条低质量数据
- **数字类问题是关键**: 必须将数字类问题占比提升到20-30%
- **人工验证不可少**: 不能完全依赖LLM自动生成数据
- **分阶段迭代**: 先解决少量高质量数据，再批量生成

---

**报告生成时间**: 2026-02-28 21:15
**分析者**: Claude Code
**版本**: 1.0
