# Qwen2.5-3B 模型训练指南

本指南将帮助你使用 Qwen2.5-3B 模型进行垂直领域训练。

## 📋 前置准备

### 1. 模型下载
模型正在后台下载中（约40%完成）。下载完成后，模型将保存在：
```
models/Qwen/Qwen2.5-3B/
```

### 2. 训练数据
已有训练数据：`data/报销细则_distilled_chunked.jsonl`
- 训练样本：863条
- 格式：JSONL (instruction-output)

### 3. 环境配置
配置文件已更新：`config.yaml`
- 模型：Qwen2.5-3B
- LoRA rank: 16
- 学习率: 0.00005
- 训练轮数: 3

## 🚀 快速开始

### 步骤1：测试训练环境
```bash
python3 test_training_setup.py
```

这会检查：
- ✅ 模型文件是否完整
- ✅ 训练数据格式是否正确
- ✅ 依赖包是否安装
- ✅ 配置文件是否正确

### 步骤2：开始训练
```bash
python3 train_3b_model.py
```

训练过程：
1. 加载配置和数据
2. 初始化训练器
3. 执行QLoRA训练
4. 保存训练好的模型

### 步骤3：测试模型
训练完成后，模型保存在：
```
outputs/qwen2_5-3b-trained/
```

## 📊 配置说明

### 针对3B模型的优化配置

| 参数 | 值 | 说明 |
|------|-----|------|
| **LoRA Rank** | 16 | 3B模型需要更强的适配能力 |
| **LoRA Alpha** | 32 | rank × 2 |
| **学习率** | 0.00005 | 更小的学习率防止过拟合 |
| **训练轮数** | 3 | 3B模型容易过拟合，减少轮数 |
| **批次大小** | 1 | 节省内存 |
| **梯度累积** | 4 | 有效批次大小 = 4 |
| **Warmup步数** | 30 | 更充分的预热 |

### 为什么这样配置？

1. **更大的LoRA rank (16 vs 12)**
   - 3B模型有更多参数，需要更大的适配空间
   - 可以更好地捕获领域知识

2. **更小的学习率 (0.00005 vs 0.0001)**
   - 大模型更容易过拟合
   - 小学习率保证稳定训练

3. **更少的训练轮数 (3 vs 5)**
   - 3B模型学习能力强，3轮足够
   - 防止过度记忆训练数据

## 💡 训练技巧

### 内存优化
如果遇到内存不足：

```yaml
# 在 config.yaml 中调整
training:
  batch_size: 1           # 保持最小
  gradient_accumulation_steps: 8  # 增加梯度累积
  max_seq_length: 256     # 减小序列长度
```

### 训练监控
训练时会显示：
- 当前轮数
- 损失值（loss）
- 训练进度

损失值应该逐渐下降，如果：
- ✅ 损失稳定下降 → 训练良好
- ⚠️ 损失波动大 → 学习率太大
- ❌ 损失不下降 → 数据或配置有问题

### 调整训练强度

**轻量训练（快速测试）：**
```yaml
training:
  num_epochs: 1
  learning_rate: 0.0001
```

**完整训练（最佳效果）：**
```yaml
training:
  num_epochs: 3
  learning_rate: 0.00005
```

**增强训练（更多数据时）：**
```yaml
training:
  num_epochs: 5
  learning_rate: 0.00003
lora:
  rank: 32
  alpha: 64
```

## 📈 预期结果

### 训练时间估算
基于863条训练数据：
- **使用MPS (Mac M1/M2)**: 约30-60分钟
- **使用CUDA GPU**: 约15-30分钟
- **使用CPU**: 约2-4小时（不推荐）

### 模型效果
训练完成后，模型应该能够：
- ✅ 准确回答财务报销相关问题
- ✅ 理解华东师范大学报销细则
- ✅ 提供符合规定的报销指导

## 🔧 故障排查

### 问题1：模型加载失败
```
错误: 找不到模型文件
解决: 运行 python3 download_qwen_3b.py
```

### 问题2：CUDA out of memory
```
错误: CUDA内存不足
解决:
  - 减小 batch_size 到 1
  - 增加 gradient_accumulation_steps
  - 或使用CPU/MPS模式
```

### 问题3：训练损失不下降
```
检查:
  1. 数据格式是否正确
  2. 学习率是否太大
  3. 数据质量是否良好
```

## 📝 训练示例

```bash
# 完整训练流程
# 1. 测试环境
python3 test_training_setup.py

# 2. 开始训练
python3 train_3b_model.py

# 3. 等待训练完成...
#    训练过程中会显示进度和损失值

# 4. 测试训练好的模型
python3 test_trained_model.py
```

## 🎯 下一步

训练完成后，你可以：

1. **测试模型效果**
   ```bash
   python3 test_trained_model.py
   ```

2. **导出为GGUF格式**（用于ollama）
   ```bash
   python3 export_to_gguf.py
   ```

3. **部署到应用**
   - 加载模型
   - 构建API服务
   - 集成到应用中

4. **进一步优化**
   - 收集更多训练数据
   - 调整训练参数
   - 尝试不同的LoRA配置

## 📚 相关文件

| 文件 | 说明 |
|------|------|
| `config.yaml` | 训练配置文件 |
| `train_3b_model.py` | 3B模型训练脚本 |
| `test_training_setup.py` | 环境测试脚本 |
| `data/报销细则_distilled_chunked.jsonl` | 训练数据 |
| `src/training/trainer.py` | 训练器核心代码 |

## 💬 常见问题

**Q: 3B模型 vs 1.5B模型？**
A: 3B模型效果更好，但需要更多内存和训练时间。如果内存有限，可以使用1.5B模型。

**Q: 训练多长时间合适？**
A: 3轮训练通常足够。如果数据量很大（>1000条），可以增加到5轮。

**Q: 如何判断训练效果？**
A: 观察损失值是否稳定下降，训练完成后用测试集评估模型回答质量。

---

**祝训练顺利！** 🎉
