#!/usr/bin/env python3
"""
å¯¹æ¯”æµ‹è¯•è„šæœ¬
å¯¹æ¯”åŸºåº§æ¨¡å‹å’Œè®­ç»ƒåæ¨¡å‹çš„è¡¨ç°å·®å¼‚
"""

import sys
from pathlib import Path

# æ·»åŠ srcåˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent / "src"))

from inference import ModelInferencer


class ModelComparator:
    """æ¨¡å‹å¯¹æ¯”å™¨"""

    def __init__(self, base_model_path: str, trained_model_path: str):
        self.base_model_path = base_model_path
        self.trained_model_path = trained_model_path
        self.base_inferencer = None
        self.trained_inferencer = None

    def load_models(self):
        """åŠ è½½ä¸¤ä¸ªæ¨¡å‹"""
        print("=" * 70)
        print("ğŸ”„ åŠ è½½æ¨¡å‹")
        print("=" * 70)

        print("\n1ï¸âƒ£ åŠ è½½åŸºåº§æ¨¡å‹ï¼ˆæœªè®­ç»ƒï¼‰...")
        self.base_inferencer = ModelInferencer(
            self.base_model_path,
            self.base_model_path
        )
        self.base_inferencer.load_model()
        print("âœ… åŸºåº§æ¨¡å‹åŠ è½½å®Œæˆ\n")

        print("2ï¸âƒ£ åŠ è½½è®­ç»ƒåæ¨¡å‹...")
        self.trained_inferencer = ModelInferencer(
            self.trained_model_path,
            self.base_model_path  # ä½¿ç”¨ç›¸åŒçš„åŸºåº§
        )
        self.trained_inferencer.load_model()
        print("âœ… è®­ç»ƒåæ¨¡å‹åŠ è½½å®Œæˆ\n")

    def compare_single_question(
        self,
        question: str,
        expected_keywords: list = None,
        temperature: float = 0.1
    ):
        """
        å¯¹æ¯”å•ä¸ªé—®é¢˜çš„å›ç­”

        Args:
            question: æµ‹è¯•é—®é¢˜
            expected_keywords: æœŸæœ›çš„å…³é”®è¯
            temperature: ç”Ÿæˆæ¸©åº¦
        """
        print("=" * 70)
        print(f"â“ é—®é¢˜: {question}")
        print("=" * 70)

        if expected_keywords:
            print(f"ğŸ“Œ æœŸæœ›å…³é”®è¯: {', '.join(expected_keywords)}")

        # åŸºåº§æ¨¡å‹å›ç­”
        print("\nğŸ”µ åŸºåº§æ¨¡å‹å›ç­”:")
        base_response = self.base_inferencer.generate(
            question,
            max_new_tokens=300,
            temperature=temperature,
            repetition_penalty=1.0,
        )
        print(f"  {base_response}")

        if expected_keywords:
            base_found = [kw for kw in expected_keywords if kw in base_response]
            print(f"  âœ“ å…³é”®è¯åŒ¹é…: {', '.join(base_found) if base_found else 'æ— '}")

        # è®­ç»ƒåæ¨¡å‹å›ç­”
        print("\nğŸŸ¢ è®­ç»ƒåæ¨¡å‹å›ç­”:")
        trained_response = self.trained_inferencer.generate(
            question,
            max_new_tokens=300,
            temperature=temperature,
            repetition_penalty=1.0,
        )
        print(f"  {trained_response}")

        if expected_keywords:
            trained_found = [kw for kw in expected_keywords if kw in trained_response]
            print(f"  âœ“ å…³é”®è¯åŒ¹é…: {', '.join(trained_found) if trained_found else 'æ— '}")

        # å¯¹æ¯”åˆ†æ
        print("\nğŸ“Š å¯¹æ¯”åˆ†æ:")

        # 1. å…³é”®è¯å¯¹æ¯”
        if expected_keywords:
            base_coverage = len(base_found) / len(expected_keywords)
            trained_coverage = len(trained_found) / len(expected_keywords)

            print(f"  åŸºåº§æ¨¡å‹å…³é”®è¯è¦†ç›–ç‡: {base_coverage*100:.1f}%")
            print(f"  è®­ç»ƒåæ¨¡å‹å…³é”®è¯è¦†ç›–ç‡: {trained_coverage*100:.1f}%")

            if trained_coverage > base_coverage:
                improvement = (trained_coverage - base_coverage) * 100
                print(f"  âœ… æå‡: +{improvement:.1f}%")
            elif trained_coverage < base_coverage:
                decline = (base_coverage - trained_coverage) * 100
                print(f"  âš ï¸  ä¸‹é™: -{decline:.1f}%")
            else:
                print(f"  â¡ï¸  æŒå¹³")

        # 2. å›ç­”é•¿åº¦å¯¹æ¯”
        base_len = len(base_response)
        trained_len = len(trained_response)
        print(f"\n  åŸºåº§æ¨¡å‹å›ç­”é•¿åº¦: {base_len} å­—ç¬¦")
        print(f"  è®­ç»ƒåæ¨¡å‹å›ç­”é•¿åº¦: {trained_len} å­—ç¬¦")

        # 3. å†…å®¹è´¨é‡è¯„ä¼°ï¼ˆä¸»è§‚ï¼‰
        print(f"\nğŸ’¡ ä¸»è§‚è¯„ä¼°:")
        if trained_coverage > base_coverage:
            print(f"  âœ… è®­ç»ƒåæ¨¡å‹åœ¨å…³é”®è¯åŒ¹é…ä¸Šè¡¨ç°æ›´å¥½")
        elif "åä¸œå¸ˆå¤§" in trained_response or "åä¸œå¸ˆèŒƒå¤§å­¦" in trained_response:
            print(f"  âœ… è®­ç»ƒåæ¨¡å‹æ›´å¥½åœ°é€‚åº”äº†é¢†åŸŸï¼ˆåä¸œå¸ˆèŒƒå¤§å­¦ï¼‰")
        elif base_response == trained_response:
            print(f"  âš ï¸  ä¸¤ä¸ªæ¨¡å‹å›ç­”ç›¸åŒï¼Œè®­ç»ƒæ•ˆæœä¸æ˜æ˜¾")
        else:
            print(f"  ğŸ“ ä¸¤ä¸ªæ¨¡å‹å›ç­”ä¸åŒï¼Œéœ€äººå·¥åˆ¤æ–­ä¼˜åŠ£")

        print()

    def compare_batch(
        self,
        test_cases: list,
        temperature: float = 0.1
    ):
        """
        æ‰¹é‡å¯¹æ¯”æµ‹è¯•

        Args:
            test_cases: æµ‹è¯•ç”¨ä¾‹åˆ—è¡¨
            temperature: ç”Ÿæˆæ¸©åº¦
        """
        print("=" * 70)
        print("ğŸ“‹ æ‰¹é‡å¯¹æ¯”æµ‹è¯•")
        print("=" * 70)
        print(f"æµ‹è¯•ç”¨ä¾‹æ•°: {len(test_cases)}\n")

        base_better = 0
        trained_better = 0
        tie = 0

        for i, case in enumerate(test_cases, 1):
            question = case["question"]
            keywords = case.get("keywords", [])
            description = case.get("description", f"æµ‹è¯•{i}")

            print(f"[{i}/{len(test_cases)}] {description}")
            self.compare_single_question(question, keywords, temperature)

            # ç»Ÿè®¡ï¼ˆåŸºäºå…³é”®è¯è¦†ç›–ï¼‰
            if keywords:
                base_response = self.base_inferencer.generate(
                    question, max_new_tokens=300, temperature=temperature
                )
                trained_response = self.trained_inferencer.generate(
                    question, max_new_tokens=300, temperature=temperature
                )

                base_found = len([kw for kw in keywords if kw in base_response])
                trained_found = len([kw for kw in keywords if kw in trained_response])

                if trained_found > base_found:
                    trained_better += 1
                elif base_found > trained_found:
                    base_better += 1
                else:
                    tie += 1

        # æ€»ç»“
        total = len(test_cases)
        print("=" * 70)
        print("ğŸ“Š æ‰¹é‡å¯¹æ¯”æ€»ç»“")
        print("=" * 70)
        print(f"æ€»æµ‹è¯•æ•°: {total}")
        print(f"è®­ç»ƒåæ¨¡å‹æ›´å¥½: {trained_better} ({trained_better/total*100:.1f}%)")
        print(f"åŸºåº§æ¨¡å‹æ›´å¥½: {base_better} ({base_better/total*100:.1f}%)")
        print(f"æŒå¹³: {tie} ({tie/total*100:.1f}%)")

        if trained_better > base_better:
            print(f"\nâœ… ç»“è®º: è®­ç»ƒåæ¨¡å‹æ•´ä½“è¡¨ç°ä¼˜äºåŸºåº§æ¨¡å‹")
        elif base_better > trained_better:
            print(f"\nâš ï¸  ç»“è®º: åŸºåº§æ¨¡å‹è¡¨ç°æ›´å¥½ï¼Œéœ€è¦æ£€æŸ¥è®­ç»ƒé…ç½®")
        else:
            print(f"\nâ¡ï¸  ç»“è®º: ä¸¤ä¸ªæ¨¡å‹è¡¨ç°ç›¸å½“")

        print("=" * 70 + "\n")


def main():
    """ä¸»å¯¹æ¯”æµç¨‹"""
    print("=" * 70)
    print("âš–ï¸  æ¨¡å‹å¯¹æ¯”æµ‹è¯•ç³»ç»Ÿ")
    print("=" * 70)
    print()

    # æ¨¡å‹è·¯å¾„
    base_model = "models/Qwen/Qwen2.5-3B"
    trained_model = "outputs/qwen2_5-3b-trained"

    # åˆå§‹åŒ–å¯¹æ¯”å™¨
    comparator = ModelComparator(base_model, trained_model)
    comparator.load_models()

    # æµ‹è¯•ç”¨ä¾‹
    test_cases = [
        {
            "question": "å¯¹äºè¯¾é¢˜åä½œè´¹ã€åˆ¶ä½œè´¹ã€ææ–™è´¹ç­‰è´¹ç”¨ï¼Œåä¸œå¸ˆèŒƒå¤§å­¦å¯¹åè®®å’ŒåˆåŒçš„ç­¾è®¢é‡‘é¢æœ‰ä»€ä¹ˆå…·ä½“è¦æ±‚ï¼Ÿ",
            "keywords": ["3000", "10000", "åè®®", "åˆåŒ"],
            "description": "é‡‘é¢é˜ˆå€¼è®°å¿†æµ‹è¯•"
        },
        {
            "question": "å·®æ—…è´¹çš„æŠ¥é”€éœ€è¦æä¾›å“ªäº›ææ–™ï¼Ÿ",
            "keywords": ["å®¡æ‰¹å•", "æœºç¥¨", "å‘ç¥¨", "ä½å®¿"],
            "description": "å·®æ—…è´¹æµç¨‹æµ‹è¯•"
        },
        {
            "question": "åŠå…¬ç”¨å“500å…ƒä»¥ä¸ŠæŠ¥é”€éœ€è¦æä¾›ä»€ä¹ˆï¼Ÿ",
            "keywords": ["æ˜ç»†", "æ¸…å•", "å‘ç¥¨"],
            "description": "åŠå…¬ç”¨å“è§„å®šæµ‹è¯•"
        },
        {
            "question": "åä¸œå¸ˆèŒƒå¤§å­¦è´¢åŠ¡æŠ¥é”€ç»†åˆ™çš„åˆ¶å®šç›®çš„æ˜¯ä»€ä¹ˆï¼Ÿ",
            "keywords": ["è§„èŒƒ", "ç®¡ç†", "èµ„é‡‘", "æ•ˆç›Š"],
            "description": "åˆ¶åº¦ç›®æ ‡æµ‹è¯•"
        },
    ]

    # æ‰¹é‡å¯¹æ¯”
    comparator.compare_batch(test_cases, temperature=0.1)

    # å•ä¸ªé—®é¢˜æ·±å…¥å¯¹æ¯”
    print("\n" + "=" * 70)
    print("ğŸ” æ·±åº¦å¯¹æ¯”åˆ†æ")
    print("=" * 70)
    comparator.compare_single_question(
        "è¯·è¯¦ç»†è¯´æ˜å·®æ—…è´¹æŠ¥é”€çš„å®Œæ•´æµç¨‹å’Œæ‰€éœ€ææ–™",
        expected_keywords=["å®¡æ‰¹", "æœºç¥¨", "å‘ç¥¨", "ä½å®¿", "æŠ¥é”€"],
        temperature=0.3
    )

    return True


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
