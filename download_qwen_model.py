#!/usr/bin/env python3
"""
ä¸‹è½½ Qwen2.5-0.5B æ¨¡å‹
æ”¯æŒä½¿ç”¨é•œåƒç«™ç‚¹åŠ é€Ÿä¸‹è½½
"""

import os
import sys
from pathlib import Path

def download_model_with_mirror():
    """ä½¿ç”¨é•œåƒä¸‹è½½æ¨¡å‹"""

    # è®¾ç½® HuggingFace é•œåƒï¼ˆä¸­å›½å¤§é™†å¯ç”¨ï¼‰
    mirrors = [
        "https://hf-mirror.com",  # ä¸»è¦é•œåƒ
        "https://huggingface.co",  # å®˜æ–¹æº
    ]

    model_id = "Qwen/Qwen2.5-0.5B"

    print("=" * 70)
    print("ä¸‹è½½ Qwen2.5-0.5B æ¨¡å‹")
    print("=" * 70)
    print(f"\næ¨¡å‹: {model_id}")
    print(f"å¤§å°: ~1 GB (500M å‚æ•°ï¼ŒFP32 ç²¾åº¦)")
    print(f"é¢„è®¡æ—¶é—´: 5-15 åˆ†é’Ÿ (å–å†³äºç½‘ç»œé€Ÿåº¦)\n")

    # å°è¯•ä¸åŒçš„é•œåƒ
    for i, mirror in enumerate(mirrors, 1):
        print(f"å°è¯•é•œåƒ #{i}: {mirror}")

        # è®¾ç½®ç¯å¢ƒå˜é‡
        os.environ['HF_ENDPOINT'] = mirror

        try:
            from transformers import AutoModelForCausalLM, AutoTokenizer
            from huggingface_hub import snapshot_download

            # ä¸‹è½½æ¨¡å‹åˆ°ç¼“å­˜ç›®å½•
            print("  å¼€å§‹ä¸‹è½½...")
            cache_dir = Path.home() / '.cache' / 'huggingface' / 'hub'

            # ä½¿ç”¨ snapshot_download ä¸‹è½½å®Œæ•´æ¨¡å‹
            model_path = snapshot_download(
                repo_id=model_id,
                cache_dir=cache_dir,
                local_dir=None,  # ä½¿ç”¨ç¼“å­˜
                local_dir_use_symlinks=False,
                resume_download=True
            )

            print(f"\nâœ… æ¨¡å‹ä¸‹è½½æˆåŠŸï¼")
            print(f"   è·¯å¾„: {model_path}")

            # æµ‹è¯•åŠ è½½
            print("\næµ‹è¯•åŠ è½½æ¨¡å‹...")
            tokenizer = AutoTokenizer.from_pretrained(model_id)
            model = AutoModelForCausalLM.from_pretrained(
                model_id,
                torch_dtype="auto",
                device_map="auto"
            )

            print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")
            print(f"   å‚æ•°é‡: {model.num_parameters() / 1e6:.1f}M")
            print(f"   æ•°æ®ç±»å‹: {model.dtype}")

            return True

        except Exception as e:
            error_msg = str(e)
            print(f"  âŒ å¤±è´¥: {error_msg[:100]}")

            if i < len(mirrors):
                print(f"  å°è¯•ä¸‹ä¸€ä¸ªé•œåƒ...\n")
            else:
                print("\næ‰€æœ‰é•œåƒéƒ½å¤±è´¥äº†ã€‚")
                return False

def download_model_manual():
    """
    æ‰‹åŠ¨ä¸‹è½½è¯´æ˜
    """
    print("\n" + "=" * 70)
    print("æ‰‹åŠ¨ä¸‹è½½è¯´æ˜")
    print("=" * 70)

    print("""
å¦‚æœè‡ªåŠ¨ä¸‹è½½å¤±è´¥ï¼Œä½ å¯ä»¥æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹ï¼š

æ–¹æ³• 1: ä½¿ç”¨ huggingface-cli (æ¨è)
--------------------------------------
# å®‰è£… huggingface-cli
pip3 install -U "huggingface_hub[cli]"

# ä½¿ç”¨é•œåƒä¸‹è½½
HF_ENDPOINT=https://hf-mirror.com huggingface-cli download Qwen/Qwen2.5-0.5B --local-dir models/Qwen2.5-0.5B

æ–¹æ³• 2: ä½¿ç”¨ git clone
--------------------------------------
# å®‰è£… git-lfs
brew install git-lfs
git lfs install

# å…‹éš†æ¨¡å‹ä»“åº“
git clone https://hf-mirror.com/Qwen/Qwen2.5-0.5B models/Qwen2.5-0.5B

æ–¹æ³• 3: ç›´æ¥ä¸‹è½½æ–‡ä»¶
--------------------------------------
1. è®¿é—®: https://hf-mirror.com/Qwen/Qwen2.5-0.5B/tree/main
2. ä¸‹è½½ä»¥ä¸‹æ–‡ä»¶åˆ° models/Qwen2.5-0.5B/:
   - config.json
   - model.safetensors (æˆ– pytorch_model.bin)
   - tokenizer.json
   - tokenizer_config.json
   - special_tokens_map.json
   - vocab.json
   - merges.txt

ä¸‹è½½å®Œæˆåï¼Œä¿®æ”¹é…ç½®æ–‡ä»¶ config.yaml:
model:
  base_model: "models/Qwen2.5-0.5B"
""")

if __name__ == "__main__":
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                 Qwen2.5-0.5B æ¨¡å‹ä¸‹è½½å·¥å…·                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")

    # è‡ªåŠ¨ä¸‹è½½
    success = download_model_with_mirror()

    if not success:
        # æ˜¾ç¤ºæ‰‹åŠ¨ä¸‹è½½è¯´æ˜
        download_model_manual()

        print("\n" + "=" * 70)
        print("ğŸ’¡ æç¤º")
        print("=" * 70)
        print("""
1. ç¡®ä¿ç½‘ç»œè¿æ¥æ­£å¸¸
2. å¦‚æœåœ¨ä¸­å›½å¤§é™†ï¼Œå»ºè®®ä½¿ç”¨ VPN æˆ–é•œåƒç«™ç‚¹
3. æ¨¡å‹æ–‡ä»¶è¾ƒå¤§ (~1GB)ï¼Œè¯·è€å¿ƒç­‰å¾…
4. ä¸‹è½½æˆåŠŸåï¼Œæ¨¡å‹ä¼šç¼“å­˜åˆ° ~/.cache/huggingface/hub/
        """)
