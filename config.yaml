# SLM Trainer Configuration - Qwen2.5-3B 优化版

# Model settings
model:
  base_model: "models/Qwen/Qwen2.5-3B"  # 使用3B模型（更强能力）✅ 已下载
  # base_model: "models/Qwen/Qwen2.5-1.5B"  # 回退到1.5B（如需要更小模型）
  # base_model: "models/Qwen/Qwen2.5-0.5B"  # 回退到0.5B（最小模型）
  max_seq_length: 512  # 序列长度

# LoRA settings - 针对3B模型优化
lora:
  rank: 16         # 增加LoRA秩（从12到16）- 3B模型需要更强的适配能力
  alpha: 32        # 相应增加alpha（rank * 2）
  dropout: 0.05

# Training settings - 3B模型优化版
training:
  batch_size: 1  # 保持小batch size以节省内存
  learning_rate: 0.00005  # 降低学习率（从0.0001到0.00005）- 3B模型需要更小的学习率
  num_epochs: 3          # 3B模型过拟合风险高，减少轮数（从5到3）
  warmup_steps: 30        # 增加warmup步数（从20到30）
  gradient_accumulation_steps: 4  # 有效批次大小 = 1×4 = 4

# Paths
paths:
  data_dir: "./data"
  model_dir: "./models"
  output_dir: "./outputs"
