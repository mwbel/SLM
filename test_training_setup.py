#!/usr/bin/env python3
"""
æµ‹è¯•è®­ç»ƒç¯å¢ƒ
éªŒè¯æ¨¡å‹ã€æ•°æ®å’Œä¾èµ–æ˜¯å¦æ­£ç¡®é…ç½®
"""

import sys
import json
from pathlib import Path
import yaml


def check_model():
    """æ£€æŸ¥æ¨¡å‹æ–‡ä»¶"""
    print("\nğŸ” æ£€æŸ¥æ¨¡å‹...")

    config_path = Path(__file__).parent / "config.yaml"
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)

    model_path = Path(config['model']['base_model'])

    # æ£€æŸ¥æ¨¡å‹è·¯å¾„
    if model_path.exists():
        print(f"âœ… æ¨¡å‹è·¯å¾„å­˜åœ¨: {model_path}")

        # æ£€æŸ¥å¿…è¦æ–‡ä»¶
        required_files = [
            "config.json",
            "tokenizer.json",
            "tokenizer_config.json"
        ]

        # æ£€æŸ¥æ¨¡å‹æƒé‡æ–‡ä»¶
        has_safetensors = False
        for file in model_path.glob("*.safetensors"):
            has_safetensors = True
            size_gb = file.stat().st_size / (1024**3)
            print(f"   âœ“ {file.name} ({size_gb:.2f} GB)")

        if not has_safetensors:
            print("   âš ï¸  æœªæ‰¾åˆ°.safetensorsæ–‡ä»¶")

        # æ£€æŸ¥é…ç½®æ–‡ä»¶
        for file_name in required_files:
            file_path = model_path / file_name
            if file_path.exists():
                print(f"   âœ“ {file_name}")
            else:
                print(f"   âœ— ç¼ºå°‘ {file_name}")

        return True
    else:
        print(f"âŒ æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}")
        print(f"   è¯·å…ˆè¿è¡Œ: python3 download_qwen_3b.py")
        return False


def check_data():
    """æ£€æŸ¥è®­ç»ƒæ•°æ®"""
    print("\nğŸ” æ£€æŸ¥è®­ç»ƒæ•°æ®...")

    data_path = Path(__file__).parent / "data" / "æŠ¥é”€ç»†åˆ™_distilled_chunked.jsonl"

    if not data_path.exists():
        print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_path}")
        return False

    print(f"âœ… æ•°æ®æ–‡ä»¶å­˜åœ¨: {data_path}")

    # æ£€æŸ¥æ•°æ®æ ¼å¼
    try:
        with open(data_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()

        print(f"   æ€»è¡Œæ•°: {len(lines)}")

        # éªŒè¯JSONæ ¼å¼
        valid_count = 0
        for i, line in enumerate(lines[:5]):  # æ£€æŸ¥å‰5è¡Œ
            try:
                data = json.loads(line.strip())
                if 'instruction' in data and 'output' in data:
                    valid_count += 1
            except json.JSONDecodeError:
                print(f"   âš ï¸  ç¬¬{i+1}è¡Œæ ¼å¼é”™è¯¯")

        if valid_count > 0:
            print(f"   âœ… æ•°æ®æ ¼å¼æ­£ç¡®ï¼ˆå‰5è¡ŒéªŒè¯é€šè¿‡ï¼‰")

            # æ˜¾ç¤ºä¸€ä¸ªæ ·æœ¬
            sample = json.loads(lines[0].strip())
            print(f"\n   ç¤ºä¾‹æ ·æœ¬:")
            print(f"   é—®é¢˜: {sample['instruction'][:60]}...")
            print(f"   å›ç­”: {sample['output'][:60]}...")

            return True
        else:
            print(f"   âŒ æ•°æ®æ ¼å¼é”™è¯¯")
            return False

    except Exception as e:
        print(f"   âŒ è¯»å–æ•°æ®å¤±è´¥: {e}")
        return False


def check_dependencies():
    """æ£€æŸ¥ä¾èµ–åŒ…"""
    print("\nğŸ” æ£€æŸ¥ä¾èµ–åŒ…...")

    required_packages = {
        'torch': 'PyTorch',
        'transformers': 'Transformers',
        'peft': 'PEFT (LoRA)',
        'datasets': 'Datasets',
        'yaml': 'PyYAML'
    }

    all_ok = True
    for package, display_name in required_packages.items():
        try:
            __import__(package)
            print(f"   âœ… {display_name}")
        except ImportError:
            print(f"   âŒ {display_name} æœªå®‰è£…")
            all_ok = False

    # æ£€æŸ¥GPU/MPSæ”¯æŒ
    try:
        import torch
        if torch.cuda.is_available():
            gpu_name = torch.cuda.get_device_name(0)
            print(f"\n   âœ… CUDA GPU: {gpu_name}")
        elif torch.backends.mps.is_available():
            print(f"\n   âœ… Apple MPS (Metal Performance Shaders)")
        else:
            print(f"\n   âš ï¸  æœªæ£€æµ‹åˆ°GPUåŠ é€Ÿï¼Œå°†ä½¿ç”¨CPUï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰")
    except:
        pass

    return all_ok


def check_config():
    """æ£€æŸ¥é…ç½®æ–‡ä»¶"""
    print("\nğŸ” æ£€æŸ¥é…ç½®æ–‡ä»¶...")

    config_path = Path(__file__).parent / "config.yaml"

    if not config_path.exists():
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        return False

    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)

        print(f"âœ… é…ç½®æ–‡ä»¶æ ¼å¼æ­£ç¡®")

        # æ£€æŸ¥å…³é”®é…ç½®
        checks = [
            ('model.base_model', config.get('model', {}).get('base_model')),
            ('model.max_seq_length', config.get('model', {}).get('max_seq_length')),
            ('lora.rank', config.get('lora', {}).get('rank')),
            ('training.num_epochs', config.get('training', {}).get('num_epochs')),
            ('training.learning_rate', config.get('training', {}).get('learning_rate')),
        ]

        all_ok = True
        for key, value in checks:
            if value is not None:
                print(f"   âœ“ {key}: {value}")
            else:
                print(f"   âœ— ç¼ºå°‘é…ç½®: {key}")
                all_ok = False

        return all_ok

    except Exception as e:
        print(f"âŒ é…ç½®æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
        return False


def main():
    """ä¸»æµ‹è¯•æµç¨‹"""
    print("=" * 70)
    print("ğŸ§ª è®­ç»ƒç¯å¢ƒæµ‹è¯•")
    print("=" * 70)

    results = {
        'config': check_config(),
        'dependencies': check_dependencies(),
        'model': check_model(),
        'data': check_data()
    }

    # æ€»ç»“
    print("\n" + "=" * 70)
    print("ğŸ“Š æµ‹è¯•æ€»ç»“")
    print("=" * 70)

    all_ok = all(results.values())

    for name, ok in results.items():
        status = "âœ… é€šè¿‡" if ok else "âŒ å¤±è´¥"
        print(f"  {name}: {status}")

    print("\n" + "=" * 70)

    if all_ok:
        print("\nğŸ‰ æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼")
        print("\nå¯ä»¥å¼€å§‹è®­ç»ƒ:")
        print("  python3 train_3b_model.py")
        print()
    else:
        print("\nâš ï¸  éƒ¨åˆ†æ£€æŸ¥å¤±è´¥ï¼Œè¯·å…ˆè§£å†³ä¸Šè¿°é—®é¢˜")
        print()

    return all_ok


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
