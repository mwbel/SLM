# 第二阶段优化结果报告

**报告日期**: 2026-02-28
**优化阶段**: 第二阶段 - 数据增强与重新训练
**状态**: ❌ 优化失败 - 性能倒退

---

## 📊 执行总结

### 优化目标
- 提升数字类问题准确率：从 0% → 80%+
- 提升整体严格模式准确率：从 40% → 70%+
- 提升关键测试用例通过率

### 实际结果
- ❌ **整体严格模式准确率**: 40% → 25% (**下降15%**)
- ❌ **关键测试用例准确率**: 未知 → 0% (**完全失败**)
- ❌ **数字类问题准确率**: 0% → 0% (**无改善**)
- ⚠️ **模型出现数字幻觉**: 开始编造不存在的数字

---

## 🔍 详细对比分析

### 1. 整体准确率对比（严格模式）

| 测试集 | 原始模型 | 优化后模型 | 变化 | 状态 |
|--------|---------|-----------|------|------|
| **所有测试用例** | 40% (5/12) | 25% (3/12) | **-15%** | ❌ 倒退 |
| **关键测试用例** | 未测试 | 0% (0/4) | **N/A** | ❌ 失败 |
| **数字类问题** | 0% | 0% | **0%** | ❌ 无改善 |

### 2. 具体测试用例对比

| 测试用例 | 预期数字 | 原始模型回答 | 优化后回答 | 结果 |
|---------|---------|-------------|-----------|------|
| 图书合同金额 | 30000元 | 500元 | **5000元** | ❌ 数字错误 |
| 课题协作费 | 3000/10000元 | 未提供数字 | **5万元/10万元** | ❌ 数字错误 |
| 制作费材料费 | 3000/10000元 | 未提供数字 | **5000元/50万元** | ❌ 数字错误 |
| 办公用品门槛 | 500元 | 500元 | 500元 | ✅ 正确 |
| 市内交通补助 | 80元 | 未提供 | **100元** | ❌ 数字错误 |
| 差旅住宿标准 | 150/200元 | 未提供数字 | 未提供数字 | ❌ 缺失 |

### 3. 关键发现

#### 问题1: 数字幻觉 🔴

优化后的模型开始**编造数字**，这是非常严重的问题：

```
测试: 图书资料报销在什么金额以上需要附合同？
预期: 30000元
优化后: "图书、资料、软件、数据库等单价在5000元以上的，需附合同。"
问题: 5000这个数字在文档中不存在！
```

```
测试: 课题协作费在什么金额以上需要签订协议或合同？
预期: 3000元或10000元
优化后: "课题经费在5万元以上的，需要签订课题协议或课题合同。"
问题: 5万元这个数字在文档中不存在！
```

#### 问题2: 性能倒退 🔴

| 指标 | 原始模型 | 优化后 | 变化 |
|------|---------|--------|------|
| 通过测试数 | 5/12 | 3/12 | -2 |
| 准确率 | 40% | 25% | -15% |
| 平均覆盖率 | 未知 | 55.3% | - |

#### 问题3: 数字准确率无改善 🔴

- 原始模型: 0% (1/9 数字测试通过)
- 优化后模型: 0% (1/9 数字测试通过)
- **完全没有改善**

---

## 📉 失败原因分析

### 原因1: 数据优化未达预期 ⚠️

虽然更新了蒸馏提示词，但实际效果不佳：

| 指标 | 目标 | 实际 | 达成率 |
|------|------|------|--------|
| **数字类问题占比** | 30%+ | 5.4% | **18%** |
| **新增数据量** | 300+ | 298 | 99% |
| **数字问题质量** | 高 | 低 | N/A |

**分析**:
- 提示词虽然强调了数字，但智谱AI生成时未能遵循
- 5.4%的数字问题占比远低于30%目标
- 新生成的数字问题质量不高

### 原因2: 数据混合策略问题 ⚠️

采用了原始数据(863条) + 新数据(298条) = 1161条的合并策略：

```
问题分析:
- 原始数据占 74.3% (863/1161)
- 新数据占 25.7% (298/1161)
- 新数据占比太低，不足以改变模型行为

类比: 就像在一杯清水中滴入几滴墨水，
      期望整体变色，但实际效果微乎其微
```

### 原因3: 训练配置可能不当 ⚠️

当前训练配置:
- Epochs: 3
- Batch size: 1
- Gradient accumulation: 4
- Effective batch size: 4
- Learning rate: 5e-05

**可能的问题**:
- 3个epoch可能不足以让模型学到新的数字模式
- 学习率可能需要调整
- 需要更多训练轮次或更激进的学习率

### 原因4: 模型出现幻觉 🔴

**最严重的问题** - 模型开始编造不存在的数字：

```
可能原因:
1. 新旧数据中存在数字冲突
   - 原始数据: 图书合同 30000元
   - 新数据可能包含其他数字
   - 模型混淆了不同场景的数字

2. 训练过程中的数值插值
   - 模型可能在多个相似数字之间"插值"
   - 例如: 看过30000和50000，生成5000

3. 数据质量问题
   - 新生成的数据中可能包含错误数字
   - 模型学习了错误的模式
```

---

## 💡 失败的根本原因总结

### 直接原因
1. **数字类问题占比不足**: 5.4% << 30%目标
2. **新数据占比太低**: 25.7%不足以改变模型行为
3. **训练轮次可能不足**: 3 epochs可能不够

### 深层原因
1. **数据蒸馏策略失败**: LLM API未能按照提示词生成足够的高质量数字问题
2. **提示词工程不足**: 需要更强的提示词来强制LLM生成数字类问题
3. **质量把控缺失**: 没有验证新生成数据的准确性

### 系统性问题
1. **过度依赖自动化**: 完全依赖LLM自动生成数据，缺乏人工验证
2. **缺乏中间验证**: 没有在数据生成后立即检查质量
3. **优化路径错误**: 应该先解决少量高质量数据，再批量生成

---

## 🎯 改进建议

### 短期方案 (立即实施)

#### 方案1: 人工编写数字类问题 👨‍💻

**优势**: 保证质量
**成本**: 时间成本高

```python
# 手工编写30-50个高质量数字类问题
数字问题模板:
1. 金额阈值类
   - "XX费用在XX元以上需要XX？"
   - "XX金额的门槛是多少？"

2. 日期时间类
   - "XX需要在XX个工作日内完成？"
   - "XX的截止时间是XX天？"

3. 数量限制类
   - "XX最多可以报销XX元？"
   - "XX的标准是每人每天XX元？"
```

#### 方案2: 使用更强的LLM 🔋

尝试使用更强大的模型（如GPT-4）进行数据蒸馏：

```python
优势:
- GPT-4对指令遵循更好
- 可能生成更符合要求的数字问题
- 数字准确性更高

劣势:
- 成本更高
- 速率限制更严格
```

#### 方案3: 完全重新训练 🔄

不使用合并数据，仅使用新生成的数据：

```python
配置:
- 仅使用298条新数据
- 增加训练轮次: 3 → 5 epochs
- 提高学习率: 5e-05 → 1e-04
- 增加batch size: 1 → 2

风险:
- 数据量较少，可能过拟合
- 需要仔细监控验证loss
```

### 中期方案 (需要规划)

#### 方案4: 多阶段数据生成 📊

分阶段生成和验证数据：

```
阶段1: 生成50条数字问题
  → 人工验证准确性
  → 修正错误问题

阶段2: 使用验证通过的问题训练
  → 评估数字准确率
  → 分析失败案例

阶段3: 根据分析结果迭代
  → 调整提示词
  → 生成下一批数据

阶段4: 重复直到达到目标
```

#### 方案5: 数据增强技术 ✨

使用其他技术增加数字问题：

```python
1. 规则替换
   - 将"金额"问题中的数字替换为文档中的其他数字
   - 保持句子结构不变

2. 模板生成
   - 提取文档中的所有数字
   - 使用固定模板生成问题
   - 人工审核后加入训练集

3. 反向生成
   - 从文档中提取事实
   - 自动生成对应的问答对
   - 重点标注数字类事实
```

### 长期方案 (战略考虑)

#### 方案6: 考虑更大的基座模型 🚀

如果3B模型实在无法满足需求：

```python
选项1: Qwen2.5-7B
- 参数量: 7B (2.3倍)
- 预期提升: 30-50%
- 成本: 训练时间+2-3倍
- 推理速度: 慢40-60%

选项2: 优化现有3B模型
- 继续优化数据质量
- 使用更多训练数据
- 调整训练策略

建议:
先尝试方案1-5，如果都无法达到70%目标，
再考虑升级到7B模型
```

---

## 📋 下一步行动计划

### 立即行动 (今天)

1. **回滚到原始模型**
   ```bash
   使用原始checkpoint: outputs/qwen2_5-3b-trained
   而不是优化后的: outputs/checkpoint-873
   ```

2. **分析新生成数据的质量**
   ```python
   检查 data/报销细则_distilled_optimized.jsonl
   - 统计数字问题占比
   - 验证数字准确性
   - 标记错误数据
   ```

3. **手工编写30个数字类问题**
   ```python
   参考 test_cases_strict.py 中的数字测试
   为每个数字阈值编写多个问答对
   ```

### 短期行动 (本周)

4. **选择并实施一个改进方案**
   - 推荐: 方案1 (人工编写) + 方案3 (重新训练)
   - 或者: 方案2 (使用GPT-4)

5. **严格评估新模型**
   - 使用严格模式
   - 重点检查数字准确率
   - 达到80%+才算成功

### 中期行动 (本月)

6. **建立数据质量验证流程**
   ```python
   每次生成数据后:
   - 自动统计数字问题占比
   - 抽样验证数字准确性
   - 只有通过验证才用于训练
   ```

7. **文档化最佳实践**
   ```python
   - 记录有效的提示词模板
   - 总结数据质量标准
   - 建立评估基准
   ```

---

## 🎓 经验教训

### 1. 数据质量 > 数据数量

```
错误: 1161条混合数据 (74%旧 + 26%新)
正确: 少量高质量数据 (如100条精心编写)

教训: 宁可要100条高质量数据，
      也不要1000条低质量数据
```

### 2. 自动化需要验证

```
错误: 完全依赖LLM自动生成数据
正确: 人工验证 + 自动生成结合

教训: 自动化工具需要质量把关，
      不能盲目信任LLM输出
```

### 3. 分阶段迭代优于一次性大改

```
错误: 一次性生成298条数据并全部使用
正确: 先生成50条 → 验证 → 调整 → 再生成

教训: 小步快跑，快速迭代，
      在发现问题时及时调整方向
```

### 4. 严格评估至关重要

```
如果没用严格模式:
- 优化后模型可能看起来"还行"
- 但实际数字准确率为0%
- 在生产环境中会造成严重错误

严格评估的价值:
- 揭示了真实问题
- 避免了部署有缺陷的模型
- 为优化提供了明确方向
```

---

## 📊 数据文件状态

### 当前文件

| 文件 | 状态 | 用途 |
|------|------|------|
| `data/报销细则_distilled_chunked.jsonl.backup` | ✅ 保留 | 原始863条数据 |
| `data/报销细则_combined.jsonl` | ⚠️ 问题 | 863+298混合数据 |
| `data/报销细则_distilled_optimized.jsonl` | ⚠️ 需检查 | 298条新数据 |
| `outputs/qwen2_5-3b-trained` | ✅ 可用 | 原始训练模型 |
| `outputs/checkpoint-873` | ❌ 失败 | 优化后模型（不推荐使用） |

### 推荐使用

```bash
# 模型
原始模型: outputs/qwen2_5-3b-trained

# 训练数据
原始数据: data/报销细则_distilled_chunked.jsonl.backup
```

---

## ✅ 结论

### 第二阶段优化: **失败**

**主要原因**:
1. 数据优化未达预期（数字问题占比5.4% vs 目标30%）
2. 模型出现数字幻觉（编造不存在的数字）
3. 性能倒退（25% vs 40%）

**关键教训**:
- 数据质量比数量更重要
- 需要人工验证不能完全自动化
- 应该分阶段迭代而不是一次性大改

**下一步**:
- 回滚到原始模型
- 人工编写高质量数字问题
- 实施更严格的质量验证流程
- 小步迭代，持续改进

---

**报告生成时间**: 2026-02-28 20:17
**分析者**: Claude Code
**版本**: 1.0
